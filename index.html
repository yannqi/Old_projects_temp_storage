<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yannqi.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="The blog about the artificial intelligence.(Almost in CV)">
<meta property="og:type" content="website">
<meta property="og:title" content="Yang Qi&#39;s Blog">
<meta property="og:url" content="https://yannqi.github.io/index.html">
<meta property="og:site_name" content="Yang Qi&#39;s Blog">
<meta property="og:description" content="The blog about the artificial intelligence.(Almost in CV)">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yang Qi">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://yannqi.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Yang Qi's Blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Yang Qi's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yang Qi</p>
  <div class="site-description" itemprop="description">The blog about the artificial intelligence.(Almost in CV)</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://yannqi.github.io/2022/08/26/The-Illustrated-Reservoir-sampling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang Qi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yang Qi's Blog">
      <meta itemprop="description" content="The blog about the artificial intelligence.(Almost in CV)">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Yang Qi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/26/The-Illustrated-Reservoir-sampling/" class="post-title-link" itemprop="url">连续学习中的蓄水池抽样算法(The Illustrated Reservoir sampling).</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-08-26 10:30:58 / Modified: 20:30:13" itemprop="dateCreated datePublished" datetime="2022-08-26T10:30:58+08:00">2022-08-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tutorial/" itemprop="url" rel="index"><span itemprop="name">Tutorial</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <!-- toc -->
<ul>
<li><a href="#--">前言</a></li>
<li><a href="#---reservoir-sampling-">什么是Reservoir
Sampling？</a></li>
<li><a href="#--------reservoir-sampling------">蓄水池抽样算法(Reservoir
sampling)具体实现：</a>
<ul>
<li><a href="#algorithm-r-">Algorithm R：</a>
<ul>
<li><a href="#--algorithm-r------------">证明Algorithm
R每个样本被取到概率相同：</a></li>
</ul></li>
</ul></li>
</ul>
<!-- tocstop -->
<h1 id="前言">前言</h1>
<p>技术性文章决定还是用中文来写，便于理解。近期在看连续学习中有关于Replay
Method的文章时，在对数据流的采样中，reservoir sampling方法出现了很多次<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>。本文将对该方法进行梳理，并给出python实现的案例。特别感谢<strong>邱simple</strong><a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<h1 id="什么是reservoir-sampling">什么是Reservoir Sampling？</h1>
<p>Reservoir
Sampling直白翻译过来就是“蓄水池抽样”，非常具象化。维基百科定义如下<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>：</p>
<blockquote>
<p>Reservoir sampling is a family of randomized algorithms for choosing
a simple random sample, without replacement, of k items from a
population of unknown size n in a single pass over the items. The size
of the population n is not known to the algorithm and is typically too
large for all n items to fit into main memory. The population is
revealed to the algorithm over time, and the algorithm cannot look back
at previous items. At any point, the current state of the algorithm must
permit extraction of a simple random sample without replacement of size
k over the part of the population seen so far.</p>
</blockquote>
<p>直白翻译过来就是，我们的蓄水池抽样算法(Reservoir
sampling)是随机抽样算法的一种，即我们要从一组长度为<strong>n</strong>的数据中抽样出<strong>k</strong>个样本出来。但是呢，它的不同之处在于，它抽样的数据是一组未知长度的数据流(<em>莫疑惑，在数据流完之前，你是不知道这个长度<strong>n</strong>的具体数值的</em>)，而且这个数据流只流通一次，无法再返回去抽样。也就是说，你必须在数据流通的过程中，去抽样出k个样本出来，且保证所有数据被抽中的概率都是等概率的，即<span
class="math inline">\(k/n\)</span>。</p>
<p>更进一步的理解， -
<strong>平常的抽样方法</strong>：平常的抽样方式是假定有100个小球，你从100个小球里面抽10个小球出来，那么我们就从1-100取10个随机数就可以，且确保了每个小球被取到的概率都是<span
class="math inline">\(1/10\)</span>。 -
<strong>蓄水池抽样算法</strong>(Reservoir
sampling)：与我们平常的抽样方式不同，蓄水池抽样算法(Reservoir
sampling)则是假定有一个大黑盒子(你不知道里面有多少个)，小球慢慢从盒子里面一个一个滚出来，而你只需要抓取10个小球，随着时间的推移，大黑盒子里面的小球都滚完了(你此时才知道滚了100个球出来，且对于滚远的球，你不能再去抓取了)，同样你也完成了取样的10个球，且需要确保了每个小球被取到的概率都是<span
class="math inline">\(1/10\)</span>。</p>
<p>总结如下：
给定一个数据流，数据流长度N很大，且N直到处理完所有数据之前都不可知，请问如何在只遍历一遍数据（O(N)）的情况下，能够随机选取出m个不重复的数据，且每个数被选中的概率为<span
class="math inline">\(m/N\)</span>。</p>
<p>如图所示： <img src="I1.png"
alt="The illustrated Reservoir sampling." /></p>
<h1
id="蓄水池抽样算法reservoir-sampling具体实现">蓄水池抽样算法(Reservoir
sampling)具体实现：</h1>
<h2 id="algorithm-r">Algorithm R：</h2>
<p>由Alan Waterman<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>最初提出的一种简单但慢的实现方式。算法伪代码图如下所示：</p>
<figure>
<img src="I2.png" alt="pseudo code." />
<figcaption aria-hidden="true">pseudo code.</figcaption>
</figure>
<h3 id="证明algorithm-r每个样本被取到概率相同">证明Algorithm
R每个样本被取到概率相同：</h3>
<p>可以用数学归纳的方法来证明。</p>
<p><strong>数学归纳法原理</strong>：</p>
<p>例如：你有一列很长的直立着的多米诺骨牌，如果你可以： 1.
证明第一张骨牌会倒。 2.
假设只要任意一张骨牌倒了，证明与其相邻的下一张骨牌也会倒。</p>
<p>那么便可以下结论：所有的骨牌都会倒下</p>
<p><strong>证明过程：</strong> 因此， 对于<span class="math inline">\(i
\geq k\)</span>，我们需要假设在第<span
class="math inline">\((i+1)\)</span>个数据来之前，reservoir中的数据被选中的概率是<span
class="math inline">\(\frac{k}{i}\)</span>；在第<span
class="math inline">\((i+1)\)</span>个数据来之后，证明reservoir中的数据被选中的概率是<span
class="math inline">\(\frac{k}{i+1}\)</span>；这样根据数学归纳的方法，可以得到结论，当第<span
class="math inline">\(N\)</span>个数据来之后，reservoir中的数据被选中的概率是<span
class="math inline">\(\frac{k}{N}\)</span>。</p>
<p><strong>证明：</strong> 首先假设，对于<span
class="math inline">\(i&gt;k\)</span>，在<span
class="math inline">\((i+1)\)</span>个数据来之前，reservoir中的被选中的数据的概率为<span
class="math inline">\(\frac{k}{i}\)</span>。</p>
<p>则当第<span class="math inline">\((i+1)\)</span>个数据来时，<span
class="math inline">\(x_{i+1}\)</span>被选中的概率为<span
class="math inline">\(\frac{k}{i+1}\)</span>，且<span
class="math inline">\(x_{i+1}\)</span>会替代掉原有的k个候选数据中的一个，替代掉的概率为<span
class="math inline">\(\frac{k}{i+1}
\frac{1}{k}=\frac{1}{i+1}\)</span>。则原有保存在reservoir内的数据仍被保存在reservoir内的概率为<span
class="math inline">\(\frac{k}{i}\times \left(1-\frac{1}{i+1} \right) =
\frac{k}{i+1}\)</span>。则可得证。</p>
<p>因此可得到结论，当第<span
class="math inline">\(N\)</span>个数据来之后，reservoir中的数据被选中的概率是<span
class="math inline">\(\frac{k}{N}\)</span>。</p>
<h2
id="distributedparallel-reservoir-sampling-并行蓄水池抽样算法3">Distributed/Parallel
Reservoir Sampling (并行蓄水池抽样算法)<a href="#fn5"
class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></h2>
<p>上述由Alan Waterman<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>等人提出的方法虽然实现了对数据流的抽样，但是对于超级庞大的数据流，即使时间复杂度为O(N)，整个抽样流程也相当耗时。因此，利用分布式的硬件进行并行化处理，才是高效率主流的应用方式。</p>
<p>思考：如何才能并行化处理数据流呢？</p>
<p>可以把数据流分成多部分，分别在不同的机器上运算，各自获取自己的reservoir。之后根据不同机器上获取的数据流的长度，再按照比例从不同的机器上的reservoir进行抽样。</p>
<p>举例有3台机器，则把数据流<span
class="math inline">\(N\)</span>给切为三部分，即<span
class="math inline">\(N_1,N_2,N_3\)</span>分别流向不同的机器，<span
class="math inline">\(N_1+N_2+N_3=N\)</span>，在不同的机器上抽样完后获得的reservoir分别为<span
class="math inline">\(R_1,R_2,R_3\)</span>，因为我们事先不知道数据流的规模，只能对所有分支数据流都默认抽样<span
class="math inline">\(k\)</span>个样本，即<span
class="math inline">\(|R_1|=|R_2|=|R_3|\)</span>，之后按照<span
class="math inline">\(N_1,N_2,N_3\)</span>的比例，从<span
class="math inline">\(R_1,R_2,R_3\)</span>中再进行按比例抽样，组成最终的reservoir，<span
class="math inline">\(R\)</span>。</p>
<h1
id="相关代码后面用到时会补充进去">相关代码(后面用到时会补充进去)</h1>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
挖坑 # 应用场景</li>
</ul>
<p>连续学习是个很好的应用场景，因为连续学习的数据流和蓄水池抽样算法的数据流的要求几乎完全一致！因此，在很多连续学习方法中，蓄水池抽样是一个必不可少的环节。</p>
<h1 id="总结">总结</h1>
<p>蓄水池抽样算法诞生于1985年，抽样方式的确很简单，也很巧妙，非常简单美。</p>
<!-- <a id="definition"></a>
上述用于标签索引 -->
<p><!-- The same to [A low level definition](#definition) --></p>
<h1 id="引用及感谢">引用及感谢</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Jeffrey S Vitter. Random sampling
with a reservoir. ACM Transactions on Mathematical Software (TOMS),
11(1):37–57, 1985.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>蓄水池抽样算法（Reservoir Sampling）:
https://www.jianshu.com/p/7a9ea6ece2af<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Reservoir sampling :
https://en.wikipedia.org/wiki/Reservoir_sampling<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Jeffrey S Vitter. Random sampling
with a reservoir. ACM Transactions on Mathematical Software (TOMS),
11(1):37–57, 1985.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Distributed/Parallel Reservoir
Sampling:
https://ballsandbins.wordpress.com/2014/04/13/distributedparallel-reservoir-sampling/<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Jeffrey S Vitter. Random sampling
with a reservoir. ACM Transactions on Mathematical Software (TOMS),
11(1):37–57, 1985.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://yannqi.github.io/2022/07/24/CLsurvey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang Qi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yang Qi's Blog">
      <meta itemprop="description" content="The blog about the artificial intelligence.(Almost in CV)">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Yang Qi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/24/CLsurvey/" class="post-title-link" itemprop="url">A brief Introduction to Continue Learning / Life long Learning</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-24 21:30:58" itemprop="dateCreated datePublished" datetime="2022-07-24T21:30:58+08:00">2022-07-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-08-17 20:22:11" itemprop="dateModified" datetime="2022-08-17T20:22:11+08:00">2022-08-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Continue-Learning/" itemprop="url" rel="index"><span itemprop="name">Continue Learning</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Continue-Learning/Technical-tutorials/" itemprop="url" rel="index"><span itemprop="name">Technical tutorials</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <!-- toc -->
<ul>
<li><a href="#what-is-continual-learning-">What is Continual
Learning?</a>
<ul>
<li><a href="#a-high-level-definition">A high level definition.</a></li>
<li><a href="#a-low-level-definition">A low level definition.</a></li>
<li><a href="#motivation---application-scenarios">Motivation &amp;
Application scenarios</a></li>
<li><a href="#the-challenge-of-continual-learing">The Challenge of
Continual Learing</a></li>
<li><a href="#four-assumptions-of-continual-learning">Four Assumptions
of Continual Learning</a>
<ul>
<li><a href="#task-incremental-learning-the-easiest-scenario-">Task
incremental Learning(the easiest scenario)</a></li>
</ul></li>
</ul></li>
</ul>
<!-- tocstop -->
<h1 id="what-is-continual-learning">What is Continual Learning?</h1>
<h2 id="a-high-level-definition.">A high level definition.</h2>
<p>“<em>Continual Learning is the constant development of increasingly
complex behaviors; the process of building more complicated skills on
top of those already developed.</em>” --- <em>Ring(1997).CHILD: A First
Step Towards Continual Learning</em></p>
<p>Continual Learning is also referred to as lifelong Learning,
sequential learing or incremental Learning. They have the same
define.</p>
<p>“<em>Studies the problem of Learning froman infinite stream of data,
with the goal of gradually extending acquired knowledge and using it for
future Learning.</em>” --- <em>Z.Chen. Lifelong machine
Learning</em></p>
<figure>
<img src="CL1.png"
alt="Adaptive continuous Learning in a dynamic environment to learn tasks sequentially." />
<figcaption aria-hidden="true">Adaptive continuous Learning in a dynamic
environment to learn tasks sequentially.</figcaption>
</figure>
<p>In others words, Continual Learning tries to make machine like human
to adaptive continuou Learning in a dynamic environment to learn tasks
sequentially (from birth to death).</p>
<h2 id="a-low-level-definition.">A low level definition.</h2>
<p>Continual Learning(CL) is an algorithm whose goal is to make machine
Learning models train on non-stationary data (different from I.I.D.
data.) from sequential tasks.</p>
<p><a id="definition"></a> <!-- 上述用于标签索引 --></p>
<p>Take an example<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>, we define a sequence of tasks <span
class="math inline">\(D = \{D_1, \ldots, D_T\}\)</span>, where the
<em>t-th</em> task <span class="math inline">\(D_t=
\{(\mathbf{x}_i^t,y_i^t)\}_{i=1}^{n_t}\)</span> contains tuples of the
input sample <span class="math inline">\(\mathbf{x}_i^t \in
\mathcal{X}\)</span> , and it's label <span class="math inline">\(y_i^t
\in \mathcal{Y}\)</span>. The goal of the CL model is to train a single
model <span class="math inline">\(f_\theta : \mathcal{X} \rightarrow
\mathcal{Y}\)</span> parameterized by <span
class="math inline">\(\theta\)</span>, and it can predicts the label
<span class="math inline">\(y = f_\theta (\mathbf{x}) \in
\mathcal{Y}\)</span>, where <span
class="math inline">\(\mathbf{x}\)</span> is an unseen test sample from
arbitrary tsaks. And data from the previous tasks may not be seen
anymore when training future tasks.</p>
<h2 id="motivation-application-scenarios">Motivation &amp; Application
scenarios</h2>
<p>As we all know, Alpha-Go kills everyone in the Go world, however when
it face to Chess, it is powerless. Similarly, YOLO(A
<strong>model</strong> <em>you only look once</em>) can detect the dog
easily, but it can only detect the specific object. Therefore, people
look forward to a model that can resolve the aforementioned problems.
This calls for systems that adapt Continually and keep on Learning over
time.</p>
<p>And talk about the application scenarious, Continual Learning can be
used in many areas. Take some simple examples, a robot need to acquire
new skills in different environment to complish new tasks, a
self-driving car need to adapt to different environments (from a country
road to a highway to a city), and the conversational agents should adapt
to different users, situations, tasks.</p>
<figure>
<img src="CL2.png" alt="Application scenarios" />
<figcaption aria-hidden="true">Application scenarios</figcaption>
</figure>
<h2 id="the-challenge-of-continual-learing">The Challenge of Continual
Learing</h2>
<p>Nowadays, methods of realizing Continual Learning almost use Neural
Networks(CNN, TransFormer and so on). And due to the limitations of the
Neural Networks, the Continual Learning faces two major challenges,
<strong>Catastrophic Forgetting</strong> and <strong>Balance between
Learning and Forgeting(Stability vs Plasticity)</strong>.</p>
<ul>
<li><p><strong>Catastrophic Forgetting</strong>. When the data is
updated incrementally, the model will face catastrophic interference or
forgetting, which leads to the model forgetting how to solve the old
task after Learning the new task.</p>
<p>For example: A vision model, which can classify images into two
categories. First, we train the vision model by
<code>Cat vs Dog Datasets</code>, and then we get a perfect Acc(maybe
99.98%?) on current datasets. Second, we put the pre-trained model to
another datset(e.g. <code>Car vs Ship Datasets</code>) to train, and can
get a nice performance at the current datsets too. However, when we go
back to the <code>Cat vs Dog Datasets</code>, we will find that the
model forgets the previous data and can not divide them accurately. <img
src="CL3.png" alt="Application scenarios" /></p></li>
<li><p><strong>Stability vs Plasticity</strong>. For people, the faster
you learn, the faster you forget. The same is true for machines. How to
balance the relationship between them is also a challenge.</p>
<ol type="1">
<li>Stability &lt;=&gt; ability to retain the learned skills on the old
tasks</li>
<li>Plasticity &lt;=&gt; ability to adapt to a new task <img
src="CL5.png" alt="Application scenarios" /></li>
</ol></li>
</ul>
<p>Albeit a challenging problem, progress in Continual Learning has led
to real-world applications starting to emerge.</p>
<h2 id="four-assumptions-of-continual-learning">Four Assumptions of
Continual Learning</h2>
<p>Due to the general difficulty and variety of challenges in Continual
Learning, many methods relax the general setting to an easier task
incremental one.</p>
<p>Before understand the assumptions of the Continual Learing, we should
know some pre-settings. The same to <a href="#definition">A low level
definition</a></p>
<p>X - input vector</p>
<p>Y - class label</p>
<p>T - task.</p>
<blockquote>
<p>The concept '<em>task</em>' refers to an isolated training phase with
a new batch of data, belonging to a new group of classes, a new domain,
or a different output space.</p>
</blockquote>
<p><span class="math inline">\((\mathcal{X}^t,\mathcal{Y}^t)\)</span> -
Dataset for task t.</p>
<p><span class="math inline">\(\{\mathcal{Y}^t\}\)</span> - Class
labels. e.g.:Dog Cat Bird ...</p>
<p><span class="math inline">\(P(\mathcal{X}^t)\)</span> - input
distributions. For different task, <span
class="math inline">\(P(\mathcal{X}^t) \neq
P(\mathcal{X}^{t+1})\)</span></p>
<p><span class="math inline">\(f_t(\mathcal{X^t};\theta)\)</span> -The
predicted label of <span
class="math inline">\(\mathcal{Y^t}\)</span>,model is parameterized by
<span class="math inline">\(\theta\)</span></p>
<p>The four assumptions of Continual Learning : 1. <strong>Task
incremental Learning.</strong> 2. <strong>Class incremental
Learning.</strong> 3. <strong>Domain incremental Learning.</strong> 4.
<strong>Data incremental Learning / Task-Agnostic Learning.</strong></p>
<p>Task ID observed at training:</p>
<ul>
<li>Task observed at test: Task incremental Learning</li>
<li>Task not observed at test : Class incremental Learning and Domain
incremental Learning</li>
</ul>
<p>Task ID not observed at training:</p>
<ul>
<li>Data incremental Learning / Task-Agnostic Learning</li>
</ul>
<p>Detail description of four setting:</p>
<h3 id="task-incremental-learningthe-easiest-scenario">Task incremental
Learning(the easiest scenario)</h3>
<p>Task incremental learning considers a sequence of tasks, receiving
trainig data of just one task at a time to perform traing until
convergence. During this setting, models are always informed about which
task needs to be performed (both at train and test time). However, data
is no longer available for old tasks, impeding evaluation of statistical
risk for the new parameter values.</p>
<p>Express it with formulas:</p>
<blockquote>
<p>Data <span
class="math inline">\((\mathcal{X}^t,\mathcal{Y}^t)\)</span> is a
training-data of task t, the current task is <span
class="math inline">\(\mathcal{T}\)</span>.</p>
</blockquote>
<blockquote>
<p>The goal is to control <strong>the statistical risk</strong> of all
seen tasks given limited or no access to data from previous tasks <span
class="math inline">\(t &lt; \mathcal{T}\)</span>. In others words, the
research focals on optimizing the below formula parameterized by <span
class="math inline">\(\theta\)</span>: <span
class="math display">\[\sum\limits_{t=1}^{\mathcal{T}}\mathbb{E}_{(\mathcal{X}^t,\mathcal{Y}^t)}[\mathscr{L}(f_t(\mathcal{X^t};\theta),\mathcal{Y^t})],\]</span>
For the current task <span class="math inline">\(\mathcal{T}\)</span>,
<strong>the statistical risk</strong> can be approximated by <strong>the
empirical risk</strong>: <span
class="math display">\[\frac{1}{N_\mathcal{T}}\sum\limits_{t=1}^{N_\mathcal{T}}\mathscr{L}(f_t(x_i^{\mathcal{T}};\theta),y_i^{\mathcal{T}})],
\]</span> where <span class="math inline">\(N_{\mathcal{T}}\)</span> is
the number data of task <span
class="math inline">\(\mathcal{T}\)</span>.</p>
</blockquote>
<figure>
<img src="CL6.png" alt="Task incremental Learning" />
<figcaption aria-hidden="true">Task incremental Learning</figcaption>
</figure>
<p>All in all, this setting assumptions are: <span
class="math inline">\(P(\mathcal{X}^t) \neq
P(\mathcal{X}^{t+1})\)</span> and <span
class="math inline">\({\{\mathcal{Y}\}^t\neq
\{\mathcal{Y}^{t+1}\}}\)</span>(different labels when in different
task), <span class="math inline">\(P(\mathcal{Y}^t) \neq
P(\mathcal{Y}^{t+1})\)</span>, but you know which task it is when in
test.(each task has it's specific <code>task-label t</code>).</p>
<h3 id="class-incremental-learning">Class incremental Learning</h3>
<p><em>'An algorithm learns continuously from a sequential data stream
in which new classes occur. At any time, the learner is able to perform
multi-class classification for all classes observed so far.<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>'</em></p>
<figure>
<img src="CL11.png" alt="class-incremental Learning" />
<figcaption aria-hidden="true">class-incremental Learning</figcaption>
</figure>
<p>Models must be able not only to solve each task seen so far, but also
to infer which task they are presented with.(You don't know which task
you are facing) The new class labels may be added into the model in new
task.</p>
<figure>
<img src="CL7.png" alt="Class incremental Learning" />
<figcaption aria-hidden="true">Class incremental Learning</figcaption>
</figure>
<p>The setting assumptions are: <span
class="math inline">\(P(\mathcal{X}^t) \neq
P(\mathcal{X}^{t+1})\)</span> and <span
class="math inline">\({\{\mathcal{Y}\}^t\subset
\{\mathcal{Y}^{t+1}\}}\)</span>(Class incremental), <span
class="math inline">\(P(\mathcal{Y}^t) \neq
P(\mathcal{Y}^{t+1})\)</span>, and you don't know which task it is when
in test.</p>
<h3 id="domain-incremental-learning">Domain incremental Learning</h3>
<p>It defines a more general continual learning setting for any data
stream without notion of task, class or domain.</p>
<p>Models only need to solve the task at hand; they are not required to
infer which task it is. In other words, task concept is not specific
now, but it also have the task.</p>
<p>The setting assumptions are: <span
class="math inline">\({\{\mathcal{Y}\}^t=
\{\mathcal{Y}^{t+1}\}}\)</span>, <span
class="math inline">\(P(\mathcal{Y}^t) =
P(\mathcal{Y}^{t+1})\)</span>.</p>
<h3
id="data-incremental-learning-task-agnostic-learning-the-hardest-scenario">Data
incremental Learning / Task-Agnostic Learning (the hardest
scenario)</h3>
<p>Task identity is not available even at training time! Task-Agnostic
Learning has no task concept at all, and it is the ideal condition of
Continual Learning. <img src="CL10.png"
alt="Task-Agnostic Learning" /></p>
<p>For a clearer understanding <strong>Task incremental
Learning</strong>,<strong>Class incremental Learning</strong> and
<strong>Domain incremental Learning</strong>, you can see the following
images<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>:</p>
<ul>
<li><p>Split Mnist Task: Split the number into different task. <img
src="CL8.png" alt="Split Mnist Task" /></p></li>
<li><p>Permuted Mnist Task: Permute each image in MNIST after
vectorization. Actually use a group of random indexes to disrupt the
position of each element in the vector(image). Different random indexes
will generate different tasks after being disrupted. <img src="CL9.png"
alt="Split Mnist Task" /></p></li>
</ul>
<h3 id="the-difference-between-continuous-learning-and-multi-task">The
difference between Continuous Learning and Multi-Task</h3>
<p><strong>Multi-Task Gradient Dynamics: Tug-of-War(拔河拉锯)</strong>
<img src="CL19.png" alt="Multi Task" /></p>
<p>However, the tasks are not available simultaneously in CL! Need to
use some form of memory, or to modify the gradients, to still take into
account what solutions are good for previous tasks</p>
<h2 id="some-key-definitions">Some key definitions！</h2>
<h3 id="transfer-and-interference">Transfer and Interference</h3>
<p>Note: We need to maximize Transfer and minimize Interference. <img
src="CL20.png" alt="Transfer and interference" /></p>
<h3 id="possible-scenarios-in-cl">Possible Scenarios in CL</h3>
<figure>
<img src="CL21.png" alt="Possible Scenarios" />
<figcaption aria-hidden="true">Possible Scenarios</figcaption>
</figure>
<h2 id="the-method-of-continual-learning">The method of Continual
Learning</h2>
<p>Refer to Lange, M. D., et al.<a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a>, I try to draw a mind
mapping for better understand the current mainstream methods of
Continual Learning.</p>
<p>The define of each method<a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a>: ### Replay Methods As
you see, <strong>replay</strong> is the key. To realize
<strong>replay</strong>, this line of work should store samples in raw
format or generate pseudo-samples with a generative model (e.g.
GAN/diffusion model) because of privacy policy. Then, these previous
task samples are replayed while learning a new task to alleviate
forgetting. According to different ways of use, replay methods can be
divided into the following three categories:</p>
<p><strong>Rehearsal</strong> (Easy to implement, but poor performence
)</p>
<p>It is the esaiest way to understand. Just combine a limited subset of
stored samples(old tasks) into new task, and retrain the model.</p>
<ul>
<li>Advantage:
<ol type="1">
<li>Easy to implement</li>
</ol></li>
<li>Disadvantage:
<ol type="1">
<li>Be prone to overfitting the subset of stored samples.</li>
<li>Be bounded by joint training.</li>
</ol></li>
</ul>
<p><strong>Pseudo Rehearsal</strong></p>
<p>Feed random input to previous models, use the output as a
pseudo-sample. (Generative models are also used nowadays but add
training complexity.)<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></p>
<figure>
<img src="CL22.png" alt="Pseudo Rehearsal" />
<figcaption aria-hidden="true">Pseudo Rehearsal</figcaption>
</figure>
<p>Novel GR method<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a>: internal or hidden representations
are replayed that are generated by the network's own, context-modulated
feedback connections.</p>
<p><strong>Constrained Optimization</strong></p>
<p>Minimize interference with old tasks by constraining updates on the
new task. The goal is to optimize the loss on the current examples(s)
without increasing the losses on the previously learned examples.</p>
<p>Assume the examples are observed one at a time. Formulate the goal as
the following constrained optimization problem. <span
class="math display">\[\theta^{t}=\argmin_\theta \ell\left(f\left(x_{t}
; \theta\right), y_{t}\right)
\]</span> <span class="math display">\[s.t. \ell\left(f\left(x_{i} ;
\theta\right), y_{i}\right) \leq \ell\left(f\left(x_{i} ;
\theta^{t-1}\right), y_{i}\right) ; \forall i \in[0 \ldots
t-1]\]</span></p>
<p><span class="math inline">\(f(. ; \theta)\)</span> is a model
parameterized by <span class="math inline">\(\theta\)</span>, <span
class="math inline">\(\ell\)</span> is the loss function. <span
class="math inline">\(t\)</span> is the index of the current example and
<span class="math inline">\(i\)</span> indexes the previous
examples.</p>
<p>The original constraints can be rephrased to the constraints in the
gradient space:</p>
<p><span class="math display">\[
\left\langle g, g_{i}\right\rangle=\left\langle\frac{\partial
\ell\left(f\left(x_{t} ; \theta\right), y_{t}\right)}{\partial \theta},
\frac{\partial \ell\left(f\left(x_{i} ; \theta\right),
y_{i}\right)}{\partial \theta}\right\rangle \geq 0
\]</span></p>
<h3 id="regularization-based-methods">Regularization-Based Methods</h3>
<p>These method avoids storing raw inputs, prioritizing privacy, and
alleviating memory requirements. In these methods, an extra
regularization term is introduced in the loss function, to consolidate
previous knowledge when learning on new data. We can further divide
these methods into datafocused and prior-focused methods.<a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p><strong>Data-Focused Methods</strong></p>
<p>The basic building block in data-focused methods is <strong>knowledge
distillation</strong> from a previous model (trained on a previous task)
to the model being trained on the new data.</p>
<p><strong>Prior-Focused Methods</strong></p>
<p>To mitigate forgetting, prior-focused methods estimate a distribution
over the model parameters, used as prior when learning from new data.
Typically, importance of all neural network parameters is estimated,
with parameters assumed independent to ensure feasibility. During
training of later tasks, changes to important parameters are
penalized.</p>
<h3 id="parameter-isolation-methods">Parameter Isolation Methods</h3>
<p>This family dedicates different model parameters to each task, to
prevent any possible forgetting. These mehods avoid forgetting by using
different parameters for each task.</p>
<p>Best-suited for: task-incremental setting, unconstrained model
capacity, performance is the priority.</p>
<p><strong>Fixed Network Methods</strong> Network parts used for
previous tasks are masked out when learning new tasks (e.g., at neuronal
level (HAT) or at parameter level (PackNet, PathNet)</p>
<p><strong>Dynamic Architecture Methods</strong></p>
<p>When model size is not constrained: grow new branches for new tasks,
while freezing previous task parameters (RCL), or dedicate a model copy
to each task (Expert Gate), etc. <!-- # 大纲
大纲： 
介绍一下什么是CL，给一个High level的定义。(已完成)

描述动机，人们为什么研究这玩意儿？(已完成)

现存问题，这玩意儿目前存在什么问题？(已完成)

一些解决方案，人们都做了哪些尝试？ 一般都是成功的尝试，失败的尝试不好找。
需要做一个统计： 包含 最早的CL的文章出现的时间，CL逐步变得火爆起来的时间，当下CL的热点文章都有哪些。并对当下一些的热点方法进行简要讲解。

这玩意儿的未来如何，前景如何？
未来可扩展的那些方向。进行一点细致的讲解

 --></p>
<h2 id="conlusion">Conlusion</h2>
<p>TODO! Summaries will be added when i am familiar enough with this
field.</p>
<h2 id="appendix">Appendix:</h2>
<h3 id="mind-map">Mind Map</h3>
<figure>
<img src="CL23.png" alt="Mind Map" />
<figcaption aria-hidden="true">Mind Map</figcaption>
</figure>
<h3 id="some-representative-replay-methodskeep-updating">Some
representative Replay Methods(Keep updating):</h3>
<p>Only brief introduction, read the origional paper for more
information. #### iCaRL (incremental classifier and representation
learning)</p>
<p>iCaRL belongs to <strong>Rehearsal</strong> and <strong>Class
incremental Learning</strong>.</p>
<p>iCaRL, that allows learning in such a classincremental way: only the
training data for <strong>a small number of classes</strong>(NOT ALL
DATA! new data + some old data) has to be present at the same time and
<strong>new classes can be added progressively</strong>.</p>
<p>The author introduces three main components that in combination allow
iCaRL to fulfill all criteria put forth above.</p>
<ul>
<li><p>classification by a nearest-mean-of-exemplars rule</p></li>
<li><p>prioritized exemplar selection based on herding</p></li>
<li><p>representation learning using knowledge distillation and
prototype rehearsal.</p></li>
</ul>
<ol type="1">
<li><p>Classification (nearest-mean-of-exemplars)</p>
<p>Algorithm 1 describes the mean-of-exemplars classifier that is used
to classify images into the set of classes observed so far.</p>
<figure>
<img src="CL12.png" alt="Split Mnist Task" />
<figcaption aria-hidden="true">Split Mnist Task</figcaption>
</figure>
<p>where <span class="math inline">\(\mathcal{P} =
(P_1,\ldots,P_t)\)</span> is <strong>exemplar images</strong> that it
selects dynamically out of the data stream.</p>
<p>And <span class="math inline">\(t\)</span> denotes the number of
classes that have been observed so far(<span
class="math inline">\(t\)</span> increases with time).</p>
<p><span class="math inline">\(\varphi:\mathcal{X}\rightarrow
\mathbb{R}^d\)</span>, a trainable feature extractor, followed by a
single classification layer with as many sigmoid output nodes as classes
observed so far.</p>
<p>Class label <span class="math inline">\(y\in
\{1,\ldots,t\}\)</span>.</p></li>
<li><p>Training</p>
<p>For training, iCaRL processes batches of classes at a time using an
incremental learning strategy. Every time data for new classes is
available iCaRL calls an update routine (Algorithm 2)</p>
<figure>
<img src="CL13.png" alt="Split Mnist Task" />
<figcaption aria-hidden="true">Split Mnist Task</figcaption>
</figure></li>
<li><p>Other algorithm (For more detail, you can visit
10.1109/CVPR.2017.587) <img src="CL14.png" alt="Split Mnist Task" />
<img src="CL15.png" alt="Split Mnist Task" /></p></li>
</ol>
<h4 id="gem-gradient-episodic-memory-for-continual-learning6">GEM:
Gradient Episodic Memory for Continual Learning<a href="#fn9"
class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a></h4>
<p>Some important definition:</p>
<p>Note: Analogous to <strong>Transfer</strong> and
<strong>Interference</strong>. 1. <strong>Backward
transfer(BWT)</strong>, which is the influence that learning a current
task <span class="math inline">\(t\)</span> has on the performance on a
previous task <span class="math inline">\(k\)</span> (<span
class="math inline">\(k&lt;t\)</span>). - Positive Backward transfer:
There exists positive backward transfer when learning about some task t
increases the performance on some preceding task k. - Negative Backward
transfer: There also exists negative backward transfer when learning
about some task t decreases the performance on some preceding task k.
Large negative backward transfer is also known as <strong>catastrophic
forgetting</strong>. 2. <strong>Forward transfer(FWT)</strong>, which is
the influence that learning a current task t has on the performance on a
future task k (<span class="math inline">\(k&gt;t\)</span>). (Rarely
discussed because it is unpredictable) - Positive Forward transfer: In
particular, positive forward transfer is possible when the model is able
to perform “zero-shot” learning, perhaps by exploiting the structure
available in the task descriptors.</p>
<p>Evaluation:</p>
<figure>
<img src="CL16.png" alt="Evaluation" />
<figcaption aria-hidden="true">Evaluation</figcaption>
</figure>
<p>GEM:</p>
<figure>
<img src="CL17.png" alt="GEM" />
<figcaption aria-hidden="true">GEM</figcaption>
</figure>
<p>Experiments: <img src="CL18.png" alt="Experiments" /></p>
<h1 id="for-more-blogs">For More Blogs</h1>
<p><strong>TODO</strong> : The future of Continue Learning.</p>
<p><strong>TODO</strong> : Details of some papers。</p>
<h1 id="reference-acknowledgements">Reference &amp;
Acknowledgements</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Wang, Z., et al. (2022). Learning To
Prompt for Continual Learning. Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR).<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Rebuffi, S., et al. (2017). iCaRL:
Incremental Classifier and Representation Learning. 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR).<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Gido van de Ven and Andreas S.
Tolias.(2019) Three scenarios for continual learning. arXiv:1904.07734<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Lange, M. D., et al. (2022). "A
Continual Learning Survey: Defying Forgetting in Classification Tasks."
Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7):
3366-3385.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Lange, M. D., et al. (2022). "A
Continual Learning Survey: Defying Forgetting in Classification Tasks."
Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7):
3366-3385.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://icml.cc/virtual/2021/tutorial/10833 Part
of blog's pictures come from this link. Thanks :)<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>van de Ven, G. M., et al. (2020).
"Brain-inspired replay for continual learning with artificial neural
networks." Nature Communications 11(1): 4069.<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Lange, M. D., et al. (2022). "A
Continual Learning Survey: Defying Forgetting in Classification Tasks."
Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7):
3366-3385.<a href="#fnref8" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Lopez-Paz, D. and M. t. A. Ranzato
(2017). Gradient Episodic Memory for Continual Learning. Advances in
Neural Information Processing Systems, Curran Associates, Inc.<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yang Qi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>


  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>

<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="What is Continual Learning? A high level definition. A low level definition. Motivation &amp; Application scenarios The Challenge of Continual Learing Four Assumptions of Continual Learning Task inc">
<meta property="og:type" content="article">
<meta property="og:title" content="_Survey Blog_A brief Introduction to Continue Learning &#x2F; Life long Learning">
<meta property="og:url" content="https://yannqi.github.io/2022/07/24/CLsurvey/index.html">
<meta property="og:site_name" content="Yang Qi&#39;s Blog">
<meta property="og:description" content="What is Continual Learning? A high level definition. A low level definition. Motivation &amp; Application scenarios The Challenge of Continual Learing Four Assumptions of Continual Learning Task inc">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL1.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL2.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL3.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL5.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL6.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL11.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL7.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL10.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL8.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL9.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL19.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL20.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL21.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL22.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL23.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL12.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL13.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL14.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL15.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL16.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL17.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL18.png">
<meta property="article:published_time" content="2022-07-24T13:30:58.000Z">
<meta property="article:modified_time" content="2022-10-23T12:48:43.815Z">
<meta property="article:author" content="Yang Qi">
<meta property="article:tag" content="Continue Learning &#x2F; Life long Learning">
<meta property="article:tag" content="Survey">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL1.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>_Survey Blog_A brief Introduction to Continue Learning / Life long Learning</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 6.2.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/yannqi">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2022/08/26/The-Illustrated-Reservoir-sampling/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://yannqi.github.io/2022/07/24/CLsurvey/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://yannqi.github.io/2022/07/24/CLsurvey/&text=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://yannqi.github.io/2022/07/24/CLsurvey/&is_video=false&description=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning&body=Check out this article: https://yannqi.github.io/2022/07/24/CLsurvey/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://yannqi.github.io/2022/07/24/CLsurvey/&name=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://yannqi.github.io/2022/07/24/CLsurvey/&t=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#What-is-Continual-Learning"><span class="toc-number">1.</span> <span class="toc-text">What is Continual Learning?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#A-high-level-definition"><span class="toc-number">1.1.</span> <span class="toc-text">A high level definition.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-low-level-definition"><span class="toc-number">1.2.</span> <span class="toc-text">A low level definition.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation-amp-Application-scenarios"><span class="toc-number">1.3.</span> <span class="toc-text">Motivation &amp; Application scenarios</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Challenge-of-Continual-Learing"><span class="toc-number">1.4.</span> <span class="toc-text">The Challenge of Continual Learing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Four-Assumptions-of-Continual-Learning"><span class="toc-number">1.5.</span> <span class="toc-text">Four Assumptions of Continual Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Task-incremental-Learning-the-easiest-scenario"><span class="toc-number">1.5.1.</span> <span class="toc-text">Task incremental Learning(the easiest scenario)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Class-incremental-Learning"><span class="toc-number">1.5.2.</span> <span class="toc-text">Class incremental Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Domain-incremental-Learning"><span class="toc-number">1.5.3.</span> <span class="toc-text">Domain incremental Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Data-incremental-Learning-Task-Agnostic-Learning-the-hardest-scenario"><span class="toc-number">1.5.4.</span> <span class="toc-text">Data incremental Learning &#x2F; Task-Agnostic Learning (the hardest scenario)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-difference-between-Continuous-Learning-and-Multi-Task"><span class="toc-number">1.5.5.</span> <span class="toc-text">The difference between Continuous Learning and Multi-Task</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Some-key-definitions%EF%BC%81"><span class="toc-number">1.6.</span> <span class="toc-text">Some key definitions！</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transfer-and-Interference"><span class="toc-number">1.6.1.</span> <span class="toc-text">Transfer and Interference</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Possible-Scenarios-in-CL"><span class="toc-number">1.6.2.</span> <span class="toc-text">Possible Scenarios in CL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-method-of-Continual-Learning"><span class="toc-number">1.7.</span> <span class="toc-text">The method of Continual Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Replay-Methods"><span class="toc-number">1.7.1.</span> <span class="toc-text">Replay Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Regularization-Based-Methods"><span class="toc-number">1.7.2.</span> <span class="toc-text">Regularization-Based Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameter-Isolation-Methods"><span class="toc-number">1.7.3.</span> <span class="toc-text">Parameter Isolation Methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conlusion"><span class="toc-number">1.8.</span> <span class="toc-text">Conlusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Appendix"><span class="toc-number">1.9.</span> <span class="toc-text">Appendix:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Mind-Map"><span class="toc-number">1.9.1.</span> <span class="toc-text">Mind Map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Some-representative-Replay-Methods-Keep-updating"><span class="toc-number">1.9.2.</span> <span class="toc-text">Some representative Replay Methods(Keep updating):</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#iCaRL-incremental-classifier-and-representation-learning"><span class="toc-number">1.9.2.1.</span> <span class="toc-text">iCaRL (incremental classifier and representation learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GEM-Gradient-Episodic-Memory-for-Continual-Learning6"><span class="toc-number">1.9.2.2.</span> <span class="toc-text">GEM: Gradient Episodic Memory for Continual Learning6</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#For-More-Blogs"><span class="toc-number">2.</span> <span class="toc-text">For More Blogs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Reference-amp-Acknowledgements"><span class="toc-number">3.</span> <span class="toc-text">Reference &amp; Acknowledgements</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        _Survey Blog_A brief Introduction to Continue Learning / Life long Learning
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Yang Qi</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2022-07-24T13:30:58.000Z" itemprop="datePublished">2022-07-24</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Continue-Learning/">Continue Learning</a> › <a class="category-link" href="/categories/Continue-Learning/Technical-tutorials/">Technical tutorials</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Continue-Learning-Life-long-Learning/" rel="tag">Continue Learning / Life long Learning</a>, <a class="tag-link-link" href="/tags/Survey/" rel="tag">Survey</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <!-- toc -->
<ul>
<li><a href="#what-is-continual-learning-">What is Continual Learning?</a><ul>
<li><a href="#a-high-level-definition">A high level definition.</a></li>
<li><a href="#a-low-level-definition">A low level definition.</a></li>
<li><a href="#motivation---application-scenarios">Motivation &amp; Application scenarios</a></li>
<li><a href="#the-challenge-of-continual-learing">The Challenge of Continual Learing</a></li>
<li><a href="#four-assumptions-of-continual-learning">Four Assumptions of Continual Learning</a><ul>
<li><a href="#task-incremental-learning-the-easiest-scenario-">Task incremental Learning(the easiest scenario)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h1 id="What-is-Continual-Learning"><a href="#What-is-Continual-Learning" class="headerlink" title="What is Continual Learning?"></a>What is Continual Learning?</h1><h2 id="A-high-level-definition"><a href="#A-high-level-definition" class="headerlink" title="A high level definition."></a>A high level definition.</h2><p>“<em>Continual Learning is the constant development of  increasingly complex behaviors; the process of building more complicated skills on top of those already developed.</em>”              —- <em>Ring(1997).CHILD: A First Step Towards Continual Learning</em></p>
<p>Continual Learning is also referred to as lifelong Learning, sequential learing or incremental Learning. They have the same define.</p>
<p>“<em>Studies the problem of Learning froman infinite stream of data, with the goal of gradually extending acquired knowledge and using it for future Learning.</em>”  —- <em>Z.Chen. Lifelong machine Learning</em></p>
<p><img src="CL1.png" alt="Adaptive continuous Learning in a dynamic environment to learn tasks sequentially."></p>
<p>In others words, Continual Learning tries to make machine like human to adaptive continuou Learning in a dynamic environment to learn tasks sequentially (from birth to death).</p>
<h2 id="A-low-level-definition"><a href="#A-low-level-definition" class="headerlink" title="A low level definition."></a>A low level definition.</h2><p>Continual Learning(CL) is an algorithm whose goal is to make machine Learning models train on non-stationary data  (different from I.I.D. data.) from sequential tasks.</p>
<p><a id="definition"></a><br><!-- 上述用于标签索引 --></p>
<p>Take an example<sup><a href="#fn_2" id="reffn_2">2</a></sup>, we define a sequence of tasks $D = \{D_1, \ldots, D_T\}$, where the <em>t-th</em> task $D_t= \{(\mathbf{x}_i^t,y_i^t)\}_{i=1}^{n_t}$ contains tuples of the input sample $\mathbf{x}_i^t \in \mathcal{X}$ , and it’s label $y_i^t \in \mathcal{Y}$. The goal of the CL model is to train a single model $f_\theta : \mathcal{X} \rightarrow \mathcal{Y}$ parameterized by $\theta$, and it can predicts the label $y = f_\theta (\mathbf{x}) \in \mathcal{Y}$, where $\mathbf{x}$ is an unseen test sample from arbitrary tsaks. And data from the previous tasks may not be seen anymore when training future tasks.</p>
<h2 id="Motivation-amp-Application-scenarios"><a href="#Motivation-amp-Application-scenarios" class="headerlink" title="Motivation &amp; Application scenarios"></a>Motivation &amp; Application scenarios</h2><p>As we all know, Alpha-Go kills everyone in the Go world, however when it face to Chess, it is powerless.  Similarly, YOLO(A <strong>model</strong> <em>you only look once</em>) can detect the dog easily, but it can only detect the specific object.  Therefore, people look forward to a model that can resolve the aforementioned problems.  This calls for systems that adapt Continually and keep on Learning over time.</p>
<p>And talk about the application scenarious, Continual Learning can be used in many areas. Take some simple examples, a robot need to acquire new skills in different environment to complish new tasks, a self-driving car need to adapt to different environments (from a country road to a highway to a city), and the conversational agents should adapt to different users, situations, tasks. </p>
<p><img src="CL2.png" alt="Application scenarios"></p>
<h2 id="The-Challenge-of-Continual-Learing"><a href="#The-Challenge-of-Continual-Learing" class="headerlink" title="The Challenge of Continual Learing"></a>The Challenge of Continual Learing</h2><p>Nowadays, methods of realizing Continual Learning almost use Neural Networks(CNN, TransFormer and so on). And due to the limitations of the Neural Networks, the Continual Learning faces two major challenges, <strong>Catastrophic Forgetting</strong> and <strong>Balance between Learning and Forgeting(Stability vs Plasticity)</strong>.</p>
<ul>
<li><p><strong>Catastrophic Forgetting</strong>. When the data is updated incrementally, the model will face catastrophic interference or forgetting, which leads to the model forgetting how to solve the old task after Learning the new task.</p>
<p> For example: A vision model, which can classify images into two categories. First, we train the vision model by <code>Cat vs Dog Datasets</code>, and then we get a perfect Acc(maybe 99.98%?) on current datasets. Second, we put the pre-trained model to another datset(e.g. <code>Car vs Ship Datasets</code>) to train, and can get a nice performance at the current datsets too. However, when we go back to the <code>Cat vs Dog Datasets</code>, we will find that the model forgets the previous data and can not divide them accurately.<br><img src="CL3.png" alt="Application scenarios"></p>
</li>
<li><p><strong>Stability vs Plasticity</strong>.<br>For people, the faster you learn, the faster you forget. The same is true for machines. How to balance the relationship between them is also a challenge.</p>
<ol>
<li>Stability &lt;=&gt; ability to retain the learned skills on the old tasks</li>
<li>Plasticity &lt;=&gt; ability to adapt to a new task<br><img src="CL5.png" alt="Application scenarios"></li>
</ol>
</li>
</ul>
<p>Albeit a challenging problem, progress in Continual Learning has led to real-world applications starting to emerge.</p>
<h2 id="Four-Assumptions-of-Continual-Learning"><a href="#Four-Assumptions-of-Continual-Learning" class="headerlink" title="Four Assumptions of Continual Learning"></a>Four Assumptions of Continual Learning</h2><p>Due to the general difficulty and variety of challenges in Continual Learning, many methods relax the general setting to an easier task incremental one.</p>
<p>Before understand the assumptions of the Continual Learing, we should know some pre-settings. The same to <a href="#definition">A low level definition</a></p>
<p>X - input vector</p>
<p>Y - class label</p>
<p>T - task. </p>
<blockquote>
<p>The concept ‘<em>task</em>‘ refers to an isolated training phase with a new batch of data, belonging to a new group of classes, a new domain, or a different output space.</p>
</blockquote>
<p>$(\mathcal{X}^t,\mathcal{Y}^t)$ - Dataset for task t.</p>
<p>$\{\mathcal{Y}^t\}$ - Class labels. e.g.:Dog Cat Bird …</p>
<p>$P(\mathcal{X}^t)$ - input distributions. For different task, $P(\mathcal{X}^t) \neq P(\mathcal{X}^{t+1})$</p>
<p>$f_t(\mathcal{X^t};\theta)$ -The predicted label of $\mathcal{Y^t}$,model is parameterized by $\theta$</p>
<p>The four assumptions of Continual Learning : </p>
<ol>
<li><strong>Task incremental Learning.</strong> </li>
<li><strong>Class incremental Learning.</strong> </li>
<li><strong>Domain incremental Learning.</strong> </li>
<li><strong>Data incremental Learning / Task-Agnostic Learning.</strong></li>
</ol>
<p>Task ID observed at training:</p>
<ul>
<li>Task observed at test:  Task incremental Learning</li>
<li>Task not observed at test : Class incremental Learning and Domain incremental Learning</li>
</ul>
<p>Task ID not observed at training:</p>
<ul>
<li>Data incremental Learning / Task-Agnostic Learning</li>
</ul>
<p>Detail description of four setting:</p>
<h3 id="Task-incremental-Learning-the-easiest-scenario"><a href="#Task-incremental-Learning-the-easiest-scenario" class="headerlink" title="Task incremental Learning(the easiest scenario)"></a>Task incremental Learning(the easiest scenario)</h3><p>Task incremental learning considers a sequence of tasks, receiving trainig data of just one task at a time to perform traing until convergence. During this setting, models are always informed about which task needs to be performed (both at train and test time). However, data is no longer available for old tasks, impeding evaluation of statistical risk for the new parameter values.</p>
<p>Express it with formulas: </p>
<blockquote>
<p>Data $(\mathcal{X}^t,\mathcal{Y}^t)$ is a training-data of task t, the current task is $\mathcal{T}$.</p>
<p>The goal is to control <strong>the statistical risk</strong> of all seen tasks given limited or no access to data from previous tasks $t &lt; \mathcal{T}$. In others words, the research focals on optimizing the below formula parameterized by $\theta$:</p>
<script type="math/tex; mode=display">\sum\limits_{t=1}^{\mathcal{T}}\mathbb{E}_{(\mathcal{X}^t,\mathcal{Y}^t)}[\mathscr{L}(f_t(\mathcal{X^t};\theta),\mathcal{Y^t})],</script><p>For the current task $\mathcal{T}$, <strong>the statistical risk</strong> can be approximated by <strong>the empirical risk</strong>:</p>
<script type="math/tex; mode=display">\frac{1}{N_\mathcal{T}}\sum\limits_{t=1}^{N_\mathcal{T}}\mathscr{L}(f_t(x_i^{\mathcal{T}};\theta),y_i^{\mathcal{T}})],</script><p>where $N_{\mathcal{T}}$ is the number data of task $\mathcal{T}$.</p>
</blockquote>
<p><img src="CL6.png" alt="Task incremental Learning"></p>
<p>All in all, this setting assumptions are: $P(\mathcal{X}^t) \neq P(\mathcal{X}^{t+1})$ and ${\{\mathcal{Y}\}^t\neq \{\mathcal{Y}^{t+1}\}}$(different labels when in different task), $P(\mathcal{Y}^t) \neq P(\mathcal{Y}^{t+1})$, but you know which task it is when in test.(each task has it’s specific <code>task-label t</code>).</p>
<h3 id="Class-incremental-Learning"><a href="#Class-incremental-Learning" class="headerlink" title="Class incremental Learning"></a>Class incremental Learning</h3><p><em>‘An algorithm learns continuously from a sequential data stream in which new classes occur. At any time, the learner is able to perform multi-class classification for all classes observed so far.<sup><a href="#fn_5" id="reffn_5">5</a></sup>‘</em></p>
<p><img src="CL11.png" alt="class-incremental Learning"></p>
<p>Models must be able not only to solve each task seen so far, but also to infer which task they are presented with.(You don’t know which task you are facing)  The new class labels may be added into the model in new task.</p>
<p><img src="CL7.png" alt="Class incremental Learning"></p>
<p>The setting assumptions are: $P(\mathcal{X}^t) \neq P(\mathcal{X}^{t+1})$ and ${\{\mathcal{Y}\}^t\subset \{\mathcal{Y}^{t+1}\}}$(Class incremental), $P(\mathcal{Y}^t) \neq P(\mathcal{Y}^{t+1})$, and you don’t know which task it is when in test.</p>
<h3 id="Domain-incremental-Learning"><a href="#Domain-incremental-Learning" class="headerlink" title="Domain incremental Learning"></a>Domain incremental Learning</h3><p>It defines a more general continual learning setting for any data stream without notion of task, class or domain.</p>
<p>Models only need to solve the task at hand; they are not required to infer which task it is. In other words, task concept is not specific now, but it also have the task. </p>
<p>The setting assumptions are:   ${\{\mathcal{Y}\}^t= \{\mathcal{Y}^{t+1}\}}$, $P(\mathcal{Y}^t) = P(\mathcal{Y}^{t+1})$. </p>
<h3 id="Data-incremental-Learning-Task-Agnostic-Learning-the-hardest-scenario"><a href="#Data-incremental-Learning-Task-Agnostic-Learning-the-hardest-scenario" class="headerlink" title="Data incremental Learning / Task-Agnostic Learning (the hardest scenario)"></a>Data incremental Learning / Task-Agnostic Learning (the hardest scenario)</h3><p>Task identity is not available even at training time! Task-Agnostic Learning has no task concept at all, and it is the ideal condition of Continual Learning.<br><img src="CL10.png" alt="Task-Agnostic Learning"></p>
<p>For a clearer understanding <strong>Task incremental Learning</strong>,<strong>Class incremental Learning</strong> and <strong>Domain incremental Learning</strong>, you can see the following images<sup><a href="#fn_4" id="reffn_4">4</a></sup>:</p>
<ul>
<li><p>Split Mnist Task: Split the number into different task.<br><img src="CL8.png" alt="Split Mnist Task"></p>
</li>
<li><p>Permuted Mnist Task: Permute each image in MNIST after vectorization.  Actually use a group of random indexes to disrupt the position of each element in the vector(image). Different random indexes will generate different tasks after being disrupted.<br><img src="CL9.png" alt="Split Mnist Task"></p>
</li>
</ul>
<h3 id="The-difference-between-Continuous-Learning-and-Multi-Task"><a href="#The-difference-between-Continuous-Learning-and-Multi-Task" class="headerlink" title="The difference between Continuous Learning and Multi-Task"></a>The difference between Continuous Learning and Multi-Task</h3><p><strong>Multi-Task Gradient Dynamics: Tug-of-War(拔河拉锯)</strong><br><img src="CL19.png" alt="Multi Task"></p>
<p>However, the tasks are not available simultaneously in CL!<br>Need to use some form of memory, or to modify the gradients, to still take into account what solutions are good for previous tasks</p>
<h2 id="Some-key-definitions！"><a href="#Some-key-definitions！" class="headerlink" title="Some key definitions！"></a>Some key definitions！</h2><h3 id="Transfer-and-Interference"><a href="#Transfer-and-Interference" class="headerlink" title="Transfer and Interference"></a>Transfer and Interference</h3><p>Note: We need to maximize Transfer and minimize Interference.<br><img src="CL20.png" alt="Transfer and interference"></p>
<h3 id="Possible-Scenarios-in-CL"><a href="#Possible-Scenarios-in-CL" class="headerlink" title="Possible Scenarios in CL"></a>Possible Scenarios in CL</h3><p><img src="CL21.png" alt="Possible Scenarios"></p>
<h2 id="The-method-of-Continual-Learning"><a href="#The-method-of-Continual-Learning" class="headerlink" title="The method of Continual Learning"></a>The method of Continual Learning</h2><p>Refer to Lange, M. D., et al.<sup><a href="#fn_3" id="reffn_3">3</a></sup>, I try to draw a mind mapping for better understand the current mainstream methods of Continual Learning. </p>
<p>The define of each method:</p>
<h3 id="Replay-Methods"><a href="#Replay-Methods" class="headerlink" title="Replay Methods"></a>Replay Methods</h3><p>As you see, <strong>replay</strong> is the key. To realize <strong>replay</strong>, this line of work should store samples in raw format or generate pseudo-samples with a generative model (e.g. GAN/diffusion model) because of privacy policy. Then, these previous task samples are replayed while learning a new task to alleviate forgetting. According to different ways of use, replay methods can be divided into the following three categories:</p>
<p><strong>Rehearsal</strong> (Easy to implement, but poor performence )</p>
<p>It is the esaiest way to understand. Just combine a limited subset of stored samples(old tasks) into new task, and retrain the model.</p>
<ul>
<li><p>Advantage: </p>
<ol>
<li>Easy to implement</li>
</ol>
</li>
<li><p>Disadvantage: </p>
<ol>
<li>Be prone to overfitting the subset of stored samples. </li>
<li>Be bounded by joint training.</li>
</ol>
</li>
</ul>
<p><strong>Pseudo Rehearsal</strong></p>
<p>Feed random input to previous models, use the output as a pseudo-sample. (Generative models are also used nowadays but add training complexity.)<sup><a href="#fn_1" id="reffn_1">1</a></sup></p>
<p><img src="CL22.png" alt="Pseudo Rehearsal"></p>
<p>Novel GR method<sup><a href="#fn_7" id="reffn_7">7</a></sup>: internal or hidden representations are replayed that are generated by the network’s own, context-modulated feedback connections.</p>
<p><strong>Constrained Optimization</strong></p>
<p>Minimize interference with old tasks by constraining updates on the new task. The goal is to optimize the loss on the current examples(s) without increasing the losses on the previously learned examples.</p>
<p>Assume the examples are observed one at a time. Formulate the goal as the following constrained optimization problem. </p>
<script type="math/tex; mode=display">\theta^{t}=\argmin_\theta \ell\left(f\left(x_{t} ; \theta\right), y_{t}\right)
$$ $$s.t. \ell\left(f\left(x_{i} ; \theta\right), y_{i}\right) \leq \ell\left(f\left(x_{i} ; \theta^{t-1}\right), y_{i}\right) ; \forall i \in[0 \ldots t-1]</script><p>$f(. ; \theta)$ is a model parameterized by $\theta$, $\ell$ is the loss function. $t$ is the index of the current example and $i$ indexes the previous examples.</p>
<p>The original constraints can be rephrased to the constraints in the gradient space:</p>
<script type="math/tex; mode=display">
\left\langle g, g_{i}\right\rangle=\left\langle\frac{\partial \ell\left(f\left(x_{t} ; \theta\right), y_{t}\right)}{\partial \theta}, \frac{\partial \ell\left(f\left(x_{i} ; \theta\right), y_{i}\right)}{\partial \theta}\right\rangle \geq 0</script><h3 id="Regularization-Based-Methods"><a href="#Regularization-Based-Methods" class="headerlink" title="Regularization-Based Methods"></a>Regularization-Based Methods</h3><p>These method avoids storing raw inputs, prioritizing privacy, and alleviating memory requirements.<br>In these methods, an extra regularization term is introduced in the loss function, to consolidate previous knowledge when learning on new data. We can further divide these methods into datafocused and prior-focused methods.</p>
<p><strong>Data-Focused Methods</strong> </p>
<p>The basic building block in data-focused methods is <strong>knowledge distillation</strong> from a previous model (trained on a previous task) to the model being trained on the new data.</p>
<p><strong>Prior-Focused Methods</strong></p>
<p>To mitigate forgetting, prior-focused methods estimate a distribution over the model parameters, used as prior when learning from new data. Typically, importance of all neural network parameters is estimated, with parameters assumed independent to ensure feasibility. During training of later tasks, changes to important parameters are penalized.</p>
<h3 id="Parameter-Isolation-Methods"><a href="#Parameter-Isolation-Methods" class="headerlink" title="Parameter Isolation Methods"></a>Parameter Isolation Methods</h3><p>This family dedicates different model parameters to each task, to prevent any possible forgetting. These mehods avoid forgetting by using different parameters for each task.</p>
<p>Best-suited for: task-incremental setting, unconstrained model capacity, performance is the priority.</p>
<p><strong>Fixed Network Methods</strong><br>Network parts used for previous tasks are masked out when learning new tasks (e.g., at neuronal level (HAT) or at parameter level (PackNet, PathNet)</p>
<p><strong>Dynamic Architecture Methods</strong></p>
<p>When model size is not constrained: grow new branches for new tasks, while freezing previous task parameters (RCL), or dedicate a model copy to each task (Expert Gate), etc.<br>&lt;!— # 大纲<br>大纲：<br>介绍一下什么是CL，给一个High level的定义。(已完成)</p>
<p>描述动机，人们为什么研究这玩意儿？(已完成)</p>
<p>现存问题，这玩意儿目前存在什么问题？(已完成)</p>
<p>一些解决方案，人们都做了哪些尝试？ 一般都是成功的尝试，失败的尝试不好找。<br>需要做一个统计： 包含 最早的CL的文章出现的时间，CL逐步变得火爆起来的时间，当下CL的热点文章都有哪些。并对当下一些的热点方法进行简要讲解。</p>
<p>这玩意儿的未来如何，前景如何？<br>未来可扩展的那些方向。进行一点细致的讲解</p>
<p> —&gt;</p>
<h2 id="Conlusion"><a href="#Conlusion" class="headerlink" title="Conlusion"></a>Conlusion</h2><p>TODO! Summaries will be added when i am familiar enough with this field.</p>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix:"></a>Appendix:</h2><h3 id="Mind-Map"><a href="#Mind-Map" class="headerlink" title="Mind Map"></a>Mind Map</h3><p><img src="CL23.png" alt="Mind Map"></p>
<h3 id="Some-representative-Replay-Methods-Keep-updating"><a href="#Some-representative-Replay-Methods-Keep-updating" class="headerlink" title="Some representative Replay Methods(Keep updating):"></a>Some representative Replay Methods(Keep updating):</h3><p>Only brief introduction, read the origional paper for more information. </p>
<h4 id="iCaRL-incremental-classifier-and-representation-learning"><a href="#iCaRL-incremental-classifier-and-representation-learning" class="headerlink" title="iCaRL (incremental classifier and representation learning)"></a>iCaRL (incremental classifier and representation learning)</h4><p>iCaRL belongs to <strong>Rehearsal</strong> and <strong>Class incremental Learning</strong>.  </p>
<p>iCaRL, that allows learning in such a classincremental way: only the training data for <strong>a small number of classes</strong>(NOT ALL DATA! new data + some old data) has to be present at the same time and <strong>new classes can be added progressively</strong>.</p>
<p>The author introduces three main components that in combination allow iCaRL to fulfill all criteria put forth above. </p>
<ul>
<li><p>classification by a nearest-mean-of-exemplars rule</p>
</li>
<li><p>prioritized exemplar selection based on herding</p>
</li>
<li><p>representation learning using knowledge distillation and prototype rehearsal.</p>
</li>
</ul>
<ol>
<li><p>Classification (nearest-mean-of-exemplars)</p>
<p> Algorithm 1 describes the mean-of-exemplars classifier that is used to classify images into the set of classes observed so far.</p>
<p> <img src="CL12.png" alt="Split Mnist Task"></p>
<p> where $\mathcal{P} = (P_1,\ldots,P_t)$ is <strong>exemplar images</strong> that it selects dynamically out of the data stream. </p>
<p> And $t$ denotes the number of classes that have been observed so far($t$ increases with time). </p>
<p> $\varphi:\mathcal{X}\rightarrow \mathbb{R}^d$, a trainable feature extractor, followed by a single classification layer with as many sigmoid output nodes as classes observed so far.</p>
<p> Class label $y\in \{1,\ldots,t\}$. </p>
</li>
<li><p>Training</p>
<p> For training, iCaRL processes batches of classes at a time using an incremental learning strategy. Every time data for new classes is available iCaRL calls an update routine (Algorithm 2)</p>
<p> <img src="CL13.png" alt="Split Mnist Task"></p>
</li>
<li><p>Other algorithm (For more detail, you can visit 10.1109/CVPR.2017.587)<br> <img src="CL14.png" alt="Split Mnist Task"><br> <img src="CL15.png" alt="Split Mnist Task"></p>
</li>
</ol>
<h4 id="GEM-Gradient-Episodic-Memory-for-Continual-Learning6"><a href="#GEM-Gradient-Episodic-Memory-for-Continual-Learning6" class="headerlink" title="GEM: Gradient Episodic Memory for Continual Learning6"></a>GEM: Gradient Episodic Memory for Continual Learning<sup><a href="#fn_6" id="reffn_6">6</a></sup></h4><p>Some important definition:</p>
<p>Note: Analogous to <strong>Transfer</strong> and <strong>Interference</strong>.</p>
<ol>
<li><strong>Backward transfer(BWT)</strong>, which is the influence that learning a current task $t$ has on the performance on a previous task $k$ ($k&lt;t$). <ul>
<li>Positive Backward transfer: There exists positive backward transfer when learning about some task t increases the performance on some preceding task k.</li>
<li>Negative Backward transfer: There also exists negative backward transfer when learning about some task t decreases the performance on some preceding task k.  Large negative backward transfer is also known as <strong>catastrophic forgetting</strong>.</li>
</ul>
</li>
<li><strong>Forward transfer(FWT)</strong>, which is the influence that learning a current task t has on the performance on a future task k ($k&gt;t$).  (Rarely discussed because it is unpredictable)<ul>
<li>Positive Forward transfer:  In particular, positive forward transfer is possible when the model is able to perform “zero-shot” learning, perhaps by exploiting the structure available in the task descriptors.</li>
</ul>
</li>
</ol>
<p>Evaluation:</p>
<p><img src="CL16.png" alt="Evaluation"></p>
<p>GEM:</p>
<p><img src="CL17.png" alt="GEM"></p>
<p>Experiments:<br><img src="CL18.png" alt="Experiments"></p>
<h1 id="For-More-Blogs"><a href="#For-More-Blogs" class="headerlink" title="For More Blogs"></a>For More Blogs</h1><p><strong>TODO</strong> : The future of Continue Learning.</p>
<p><strong>TODO</strong> : Details of some papers。</p>
<h1 id="Reference-amp-Acknowledgements"><a href="#Reference-amp-Acknowledgements" class="headerlink" title="Reference &amp; Acknowledgements"></a>Reference &amp; Acknowledgements</h1><blockquote id="fn_1">
<sup>1</sup>. <a target="_blank" rel="noopener" href="https://icml.cc/virtual/2021/tutorial/10833">https://icml.cc/virtual/2021/tutorial/10833</a>  Part of blog’s pictures come from this link. Thanks :)<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. Wang, Z., et al. (2022). Learning To Prompt for Continual Learning. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_3">
<sup>3</sup>. Lange, M. D., et al. (2022). “A Continual Learning Survey: Defying Forgetting in Classification Tasks.” Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7): 3366-3385.<a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_4">
<sup>4</sup>. Gido van de Ven and Andreas S. Tolias.(2019) Three scenarios for continual learning. arXiv:1904.07734<a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_5">
<sup>5</sup>. Rebuffi, S., et al. (2017). iCaRL: Incremental Classifier and Representation Learning. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).<a href="#reffn_5" title="Jump back to footnote [5] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_6">
<sup>6</sup>. Lopez-Paz, D. and M. t. A. Ranzato (2017). Gradient Episodic Memory for Continual Learning. Advances in Neural Information Processing Systems, Curran Associates, Inc.<a href="#reffn_6" title="Jump back to footnote [6] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_7">
<sup>7</sup>. van de Ven, G. M., et al. (2020). “Brain-inspired replay for continual learning with artificial neural networks.” Nature Communications 11(1): 4069.<a href="#reffn_7" title="Jump back to footnote [7] in the text."> &#8617;</a>
</blockquote>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a target="_blank" rel="noopener" href="http://github.com/yannqi">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#What-is-Continual-Learning"><span class="toc-number">1.</span> <span class="toc-text">What is Continual Learning?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#A-high-level-definition"><span class="toc-number">1.1.</span> <span class="toc-text">A high level definition.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-low-level-definition"><span class="toc-number">1.2.</span> <span class="toc-text">A low level definition.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation-amp-Application-scenarios"><span class="toc-number">1.3.</span> <span class="toc-text">Motivation &amp; Application scenarios</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Challenge-of-Continual-Learing"><span class="toc-number">1.4.</span> <span class="toc-text">The Challenge of Continual Learing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Four-Assumptions-of-Continual-Learning"><span class="toc-number">1.5.</span> <span class="toc-text">Four Assumptions of Continual Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Task-incremental-Learning-the-easiest-scenario"><span class="toc-number">1.5.1.</span> <span class="toc-text">Task incremental Learning(the easiest scenario)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Class-incremental-Learning"><span class="toc-number">1.5.2.</span> <span class="toc-text">Class incremental Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Domain-incremental-Learning"><span class="toc-number">1.5.3.</span> <span class="toc-text">Domain incremental Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Data-incremental-Learning-Task-Agnostic-Learning-the-hardest-scenario"><span class="toc-number">1.5.4.</span> <span class="toc-text">Data incremental Learning &#x2F; Task-Agnostic Learning (the hardest scenario)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-difference-between-Continuous-Learning-and-Multi-Task"><span class="toc-number">1.5.5.</span> <span class="toc-text">The difference between Continuous Learning and Multi-Task</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Some-key-definitions%EF%BC%81"><span class="toc-number">1.6.</span> <span class="toc-text">Some key definitions！</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transfer-and-Interference"><span class="toc-number">1.6.1.</span> <span class="toc-text">Transfer and Interference</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Possible-Scenarios-in-CL"><span class="toc-number">1.6.2.</span> <span class="toc-text">Possible Scenarios in CL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-method-of-Continual-Learning"><span class="toc-number">1.7.</span> <span class="toc-text">The method of Continual Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Replay-Methods"><span class="toc-number">1.7.1.</span> <span class="toc-text">Replay Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Regularization-Based-Methods"><span class="toc-number">1.7.2.</span> <span class="toc-text">Regularization-Based Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameter-Isolation-Methods"><span class="toc-number">1.7.3.</span> <span class="toc-text">Parameter Isolation Methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conlusion"><span class="toc-number">1.8.</span> <span class="toc-text">Conlusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Appendix"><span class="toc-number">1.9.</span> <span class="toc-text">Appendix:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Mind-Map"><span class="toc-number">1.9.1.</span> <span class="toc-text">Mind Map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Some-representative-Replay-Methods-Keep-updating"><span class="toc-number">1.9.2.</span> <span class="toc-text">Some representative Replay Methods(Keep updating):</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#iCaRL-incremental-classifier-and-representation-learning"><span class="toc-number">1.9.2.1.</span> <span class="toc-text">iCaRL (incremental classifier and representation learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GEM-Gradient-Episodic-Memory-for-Continual-Learning6"><span class="toc-number">1.9.2.2.</span> <span class="toc-text">GEM: Gradient Episodic Memory for Continual Learning6</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#For-More-Blogs"><span class="toc-number">2.</span> <span class="toc-text">For More Blogs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Reference-amp-Acknowledgements"><span class="toc-number">3.</span> <span class="toc-text">Reference &amp; Acknowledgements</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://yannqi.github.io/2022/07/24/CLsurvey/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://yannqi.github.io/2022/07/24/CLsurvey/&text=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://yannqi.github.io/2022/07/24/CLsurvey/&is_video=false&description=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning&body=Check out this article: https://yannqi.github.io/2022/07/24/CLsurvey/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://yannqi.github.io/2022/07/24/CLsurvey/&title=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://yannqi.github.io/2022/07/24/CLsurvey/&name=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://yannqi.github.io/2022/07/24/CLsurvey/&t=_Survey Blog_A brief Introduction to Continue Learning / Life long Learning"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2021-2022
    Yang Qi
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/yannqi">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yannqi.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="What is Continual Learning?  A high level definition. A low level definition. Motivation &amp; Application scenarios The Challenge of Continual Learing Four Assumptions of Continual Lear">
<meta property="og:type" content="article">
<meta property="og:title" content="A brief Introduction to Continue Learning &#x2F; Life long Learning">
<meta property="og:url" content="https://yannqi.github.io/2022/07/24/CLsurvey/index.html">
<meta property="og:site_name" content="Yang Qi&#39;s Blog">
<meta property="og:description" content="What is Continual Learning?  A high level definition. A low level definition. Motivation &amp; Application scenarios The Challenge of Continual Learing Four Assumptions of Continual Lear">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL1.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL2.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL6.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL11.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL7.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL10.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL9.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL19.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL21.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL22.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL23.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL12.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL13.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL14.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL15.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL16.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL17.png">
<meta property="og:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL18.png">
<meta property="article:published_time" content="2022-07-24T13:30:58.000Z">
<meta property="article:modified_time" content="2022-08-17T12:22:11.719Z">
<meta property="article:author" content="Yang Qi">
<meta property="article:tag" content="Continue Learning &#x2F; Life long Learning">
<meta property="article:tag" content="Survey">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yannqi.github.io/2022/07/24/CLsurvey/CL1.png">


<link rel="canonical" href="https://yannqi.github.io/2022/07/24/CLsurvey/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://yannqi.github.io/2022/07/24/CLsurvey/","path":"2022/07/24/CLsurvey/","title":"A brief Introduction to Continue Learning / Life long Learning"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>A brief Introduction to Continue Learning / Life long Learning | Yang Qi's Blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Yang Qi's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#what-is-continual-learning"><span class="nav-number">1.</span> <span class="nav-text">What is Continual Learning?</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#a-high-level-definition."><span class="nav-number">1.1.</span> <span class="nav-text">A high level definition.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#a-low-level-definition."><span class="nav-number">1.2.</span> <span class="nav-text">A low level definition.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation-application-scenarios"><span class="nav-number">1.3.</span> <span class="nav-text">Motivation &amp; Application
scenarios</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-challenge-of-continual-learing"><span class="nav-number">1.4.</span> <span class="nav-text">The Challenge of Continual
Learing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#four-assumptions-of-continual-learning"><span class="nav-number">1.5.</span> <span class="nav-text">Four Assumptions of
Continual Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#task-incremental-learningthe-easiest-scenario"><span class="nav-number">1.5.1.</span> <span class="nav-text">Task incremental
Learning(the easiest scenario)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#class-incremental-learning"><span class="nav-number">1.5.2.</span> <span class="nav-text">Class incremental Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#domain-incremental-learning"><span class="nav-number">1.5.3.</span> <span class="nav-text">Domain incremental Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#data-incremental-learning-task-agnostic-learning-the-hardest-scenario"><span class="nav-number">1.5.4.</span> <span class="nav-text">Data
incremental Learning &#x2F; Task-Agnostic Learning (the hardest
scenario)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#the-difference-between-continuous-learning-and-multi-task"><span class="nav-number">1.5.5.</span> <span class="nav-text">The
difference between Continuous Learning and Multi-Task</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#some-key-definitions"><span class="nav-number">1.6.</span> <span class="nav-text">Some key definitionsÔºÅ</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#transfer-and-interference"><span class="nav-number">1.6.1.</span> <span class="nav-text">Transfer and Interference</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#possible-scenarios-in-cl"><span class="nav-number">1.6.2.</span> <span class="nav-text">Possible Scenarios in CL</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-method-of-continual-learning"><span class="nav-number">1.7.</span> <span class="nav-text">The method of Continual
Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#regularization-based-methods"><span class="nav-number">1.7.1.</span> <span class="nav-text">Regularization-Based Methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#parameter-isolation-methods"><span class="nav-number">1.7.2.</span> <span class="nav-text">Parameter Isolation Methods</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conlusion"><span class="nav-number">1.8.</span> <span class="nav-text">Conlusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#appendix"><span class="nav-number">1.9.</span> <span class="nav-text">Appendix:</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mind-map"><span class="nav-number">1.9.1.</span> <span class="nav-text">Mind Map</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#some-representative-replay-methodskeep-updating"><span class="nav-number">1.9.2.</span> <span class="nav-text">Some
representative Replay Methods(Keep updating):</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#gem-gradient-episodic-memory-for-continual-learning6"><span class="nav-number">1.9.2.1.</span> <span class="nav-text">GEM:
Gradient Episodic Memory for Continual Learning9</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#for-more-blogs"><span class="nav-number">2.</span> <span class="nav-text">For More Blogs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#reference-acknowledgements"><span class="nav-number">3.</span> <span class="nav-text">Reference &amp;
Acknowledgements</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yang Qi</p>
  <div class="site-description" itemprop="description">The blog about the artificial intelligence.(Almost in CV)</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yannqi" title="GitHub ‚Üí https:&#x2F;&#x2F;github.com&#x2F;yannqi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yannqi@qq.com" title="E-Mail ‚Üí mailto:yannqi@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://yannqi.github.io/2022/07/24/CLsurvey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang Qi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yang Qi's Blog">
      <meta itemprop="description" content="The blog about the artificial intelligence.(Almost in CV)">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="A brief Introduction to Continue Learning / Life long Learning | Yang Qi's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          A brief Introduction to Continue Learning / Life long Learning
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-24 21:30:58" itemprop="dateCreated datePublished" datetime="2022-07-24T21:30:58+08:00">2022-07-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-08-17 20:22:11" itemprop="dateModified" datetime="2022-08-17T20:22:11+08:00">2022-08-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Continue-Learning/" itemprop="url" rel="index"><span itemprop="name">Continue Learning</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Continue-Learning/Technical-tutorials/" itemprop="url" rel="index"><span itemprop="name">Technical tutorials</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <!-- toc -->
<ul>
<li><a href="#what-is-continual-learning-">What is Continual
Learning?</a>
<ul>
<li><a href="#a-high-level-definition">A high level definition.</a></li>
<li><a href="#a-low-level-definition">A low level definition.</a></li>
<li><a href="#motivation---application-scenarios">Motivation &amp;
Application scenarios</a></li>
<li><a href="#the-challenge-of-continual-learing">The Challenge of
Continual Learing</a></li>
<li><a href="#four-assumptions-of-continual-learning">Four Assumptions
of Continual Learning</a>
<ul>
<li><a href="#task-incremental-learning-the-easiest-scenario-">Task
incremental Learning(the easiest scenario)</a></li>
</ul></li>
</ul></li>
</ul>
<!-- tocstop -->
<h1 id="what-is-continual-learning">What is Continual Learning?</h1>
<h2 id="a-high-level-definition.">A high level definition.</h2>
<p>‚Äú<em>Continual Learning is the constant development of increasingly
complex behaviors; the process of building more complicated skills on
top of those already developed.</em>‚Äù --- <em>Ring(1997).CHILD: A First
Step Towards Continual Learning</em></p>
<p>Continual Learning is also referred to as lifelong Learning,
sequential learing or incremental Learning. They have the same
define.</p>
<p>‚Äú<em>Studies the problem of Learning froman infinite stream of data,
with the goal of gradually extending acquired knowledge and using it for
future Learning.</em>‚Äù --- <em>Z.Chen. Lifelong machine
Learning</em></p>
<figure>
<img src="CL1.png"
alt="Adaptive continuous Learning in a dynamic environment to learn tasks sequentially." />
<figcaption aria-hidden="true">Adaptive continuous Learning in a dynamic
environment to learn tasks sequentially.</figcaption>
</figure>
<p>In others words, Continual Learning tries to make machine like human
to adaptive continuou Learning in a dynamic environment to learn tasks
sequentially (from birth to death).</p>
<h2 id="a-low-level-definition.">A low level definition.</h2>
<p>Continual Learning(CL) is an algorithm whose goal is to make machine
Learning models train on non-stationary data (different from I.I.D.
data.) from sequential tasks.</p>
<p><a id="definition"></a> <!-- ‰∏äËø∞Áî®‰∫éÊ†áÁ≠æÁ¥¢Âºï --></p>
<p>Take an example<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>, we define a sequence of tasks <span
class="math inline">\(D = \{D_1, \ldots, D_T\}\)</span>, where the
<em>t-th</em> task <span class="math inline">\(D_t=
\{(\mathbf{x}_i^t,y_i^t)\}_{i=1}^{n_t}\)</span> contains tuples of the
input sample <span class="math inline">\(\mathbf{x}_i^t \in
\mathcal{X}\)</span> , and it's label <span class="math inline">\(y_i^t
\in \mathcal{Y}\)</span>. The goal of the CL model is to train a single
model <span class="math inline">\(f_\theta : \mathcal{X} \rightarrow
\mathcal{Y}\)</span> parameterized by <span
class="math inline">\(\theta\)</span>, and it can predicts the label
<span class="math inline">\(y = f_\theta (\mathbf{x}) \in
\mathcal{Y}\)</span>, where <span
class="math inline">\(\mathbf{x}\)</span> is an unseen test sample from
arbitrary tsaks. And data from the previous tasks may not be seen
anymore when training future tasks.</p>
<h2 id="motivation-application-scenarios">Motivation &amp; Application
scenarios</h2>
<p>As we all know, Alpha-Go kills everyone in the Go world, however when
it face to Chess, it is powerless. Similarly, YOLO(A
<strong>model</strong> <em>you only look once</em>) can detect the dog
easily, but it can only detect the specific object. Therefore, people
look forward to a model that can resolve the aforementioned problems.
This calls for systems that adapt Continually and keep on Learning over
time.</p>
<p>And talk about the application scenarious, Continual Learning can be
used in many areas. Take some simple examples, a robot need to acquire
new skills in different environment to complish new tasks, a
self-driving car need to adapt to different environments (from a country
road to a highway to a city), and the conversational agents should adapt
to different users, situations, tasks.</p>
<figure>
<img src="CL2.png" alt="Application scenarios" />
<figcaption aria-hidden="true">Application scenarios</figcaption>
</figure>
<h2 id="the-challenge-of-continual-learing">The Challenge of Continual
Learing</h2>
<p>Nowadays, methods of realizing Continual Learning almost use Neural
Networks(CNN, TransFormer and so on). And due to the limitations of the
Neural Networks, the Continual Learning faces two major challenges,
<strong>Catastrophic Forgetting</strong> and <strong>Balance between
Learning and Forgeting(Stability vs Plasticity)</strong>.</p>
<ul>
<li><p><strong>Catastrophic Forgetting</strong>. When the data is
updated incrementally, the model will face catastrophic interference or
forgetting, which leads to the model forgetting how to solve the old
task after Learning the new task.</p>
<p>For example: A vision model, which can classify images into two
categories. First, we train the vision model by
<code>Cat vs Dog Datasets</code>, and then we get a perfect Acc(maybe
99.98%?) on current datasets. Second, we put the pre-trained model to
another datset(e.g. <code>Car vs Ship Datasets</code>) to train, and can
get a nice performance at the current datsets too. However, when we go
back to the <code>Cat vs Dog Datasets</code>, we will find that the
model forgets the previous data and can not divide them accurately. <img
src="CL3.png" alt="Application scenarios" /></p></li>
<li><p><strong>Stability vs Plasticity</strong>. For people, the faster
you learn, the faster you forget. The same is true for machines. How to
balance the relationship between them is also a challenge.</p>
<ol type="1">
<li>Stability &lt;=&gt; ability to retain the learned skills on the old
tasks</li>
<li>Plasticity &lt;=&gt; ability to adapt to a new task <img
src="CL5.png" alt="Application scenarios" /></li>
</ol></li>
</ul>
<p>Albeit a challenging problem, progress in Continual Learning has led
to real-world applications starting to emerge.</p>
<h2 id="four-assumptions-of-continual-learning">Four Assumptions of
Continual Learning</h2>
<p>Due to the general difficulty and variety of challenges in Continual
Learning, many methods relax the general setting to an easier task
incremental one.</p>
<p>Before understand the assumptions of the Continual Learing, we should
know some pre-settings. The same to <a href="#definition">A low level
definition</a></p>
<p>X - input vector</p>
<p>Y - class label</p>
<p>T - task.</p>
<blockquote>
<p>The concept '<em>task</em>' refers to an isolated training phase with
a new batch of data, belonging to a new group of classes, a new domain,
or a different output space.</p>
</blockquote>
<p><span class="math inline">\((\mathcal{X}^t,\mathcal{Y}^t)\)</span> -
Dataset for task t.</p>
<p><span class="math inline">\(\{\mathcal{Y}^t\}\)</span> - Class
labels. e.g.:Dog Cat Bird ...</p>
<p><span class="math inline">\(P(\mathcal{X}^t)\)</span> - input
distributions. For different task, <span
class="math inline">\(P(\mathcal{X}^t) \neq
P(\mathcal{X}^{t+1})\)</span></p>
<p><span class="math inline">\(f_t(\mathcal{X^t};\theta)\)</span> -The
predicted label of <span
class="math inline">\(\mathcal{Y^t}\)</span>,model is parameterized by
<span class="math inline">\(\theta\)</span></p>
<p>The four assumptions of Continual Learning : 1. <strong>Task
incremental Learning.</strong> 2. <strong>Class incremental
Learning.</strong> 3. <strong>Domain incremental Learning.</strong> 4.
<strong>Data incremental Learning / Task-Agnostic Learning.</strong></p>
<p>Task ID observed at training:</p>
<ul>
<li>Task observed at test: Task incremental Learning</li>
<li>Task not observed at test : Class incremental Learning and Domain
incremental Learning</li>
</ul>
<p>Task ID not observed at training:</p>
<ul>
<li>Data incremental Learning / Task-Agnostic Learning</li>
</ul>
<p>Detail description of four setting:</p>
<h3 id="task-incremental-learningthe-easiest-scenario">Task incremental
Learning(the easiest scenario)</h3>
<p>Task incremental learning considers a sequence of tasks, receiving
trainig data of just one task at a time to perform traing until
convergence. During this setting, models are always informed about which
task needs to be performed (both at train and test time). However, data
is no longer available for old tasks, impeding evaluation of statistical
risk for the new parameter values.</p>
<p>Express it with formulas:</p>
<blockquote>
<p>Data <span
class="math inline">\((\mathcal{X}^t,\mathcal{Y}^t)\)</span> is a
training-data of task t, the current task is <span
class="math inline">\(\mathcal{T}\)</span>.</p>
</blockquote>
<blockquote>
<p>The goal is to control <strong>the statistical risk</strong> of all
seen tasks given limited or no access to data from previous tasks <span
class="math inline">\(t &lt; \mathcal{T}\)</span>. In others words, the
research focals on optimizing the below formula parameterized by <span
class="math inline">\(\theta\)</span>: <span
class="math display">\[\sum\limits_{t=1}^{\mathcal{T}}\mathbb{E}_{(\mathcal{X}^t,\mathcal{Y}^t)}[\mathscr{L}(f_t(\mathcal{X^t};\theta),\mathcal{Y^t})],\]</span>
For the current task <span class="math inline">\(\mathcal{T}\)</span>,
<strong>the statistical risk</strong> can be approximated by <strong>the
empirical risk</strong>: <span
class="math display">\[\frac{1}{N_\mathcal{T}}\sum\limits_{t=1}^{N_\mathcal{T}}\mathscr{L}(f_t(x_i^{\mathcal{T}};\theta),y_i^{\mathcal{T}})],
\]</span> where <span class="math inline">\(N_{\mathcal{T}}\)</span> is
the number data of task <span
class="math inline">\(\mathcal{T}\)</span>.</p>
</blockquote>
<figure>
<img src="CL6.png" alt="Task incremental Learning" />
<figcaption aria-hidden="true">Task incremental Learning</figcaption>
</figure>
<p>All in all, this setting assumptions are: <span
class="math inline">\(P(\mathcal{X}^t) \neq
P(\mathcal{X}^{t+1})\)</span> and <span
class="math inline">\({\{\mathcal{Y}\}^t\neq
\{\mathcal{Y}^{t+1}\}}\)</span>(different labels when in different
task), <span class="math inline">\(P(\mathcal{Y}^t) \neq
P(\mathcal{Y}^{t+1})\)</span>, but you know which task it is when in
test.(each task has it's specific <code>task-label t</code>).</p>
<h3 id="class-incremental-learning">Class incremental Learning</h3>
<p><em>'An algorithm learns continuously from a sequential data stream
in which new classes occur. At any time, the learner is able to perform
multi-class classification for all classes observed so far.<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>'</em></p>
<figure>
<img src="CL11.png" alt="class-incremental Learning" />
<figcaption aria-hidden="true">class-incremental Learning</figcaption>
</figure>
<p>Models must be able not only to solve each task seen so far, but also
to infer which task they are presented with.(You don't know which task
you are facing) The new class labels may be added into the model in new
task.</p>
<figure>
<img src="CL7.png" alt="Class incremental Learning" />
<figcaption aria-hidden="true">Class incremental Learning</figcaption>
</figure>
<p>The setting assumptions are: <span
class="math inline">\(P(\mathcal{X}^t) \neq
P(\mathcal{X}^{t+1})\)</span> and <span
class="math inline">\({\{\mathcal{Y}\}^t\subset
\{\mathcal{Y}^{t+1}\}}\)</span>(Class incremental), <span
class="math inline">\(P(\mathcal{Y}^t) \neq
P(\mathcal{Y}^{t+1})\)</span>, and you don't know which task it is when
in test.</p>
<h3 id="domain-incremental-learning">Domain incremental Learning</h3>
<p>It defines a more general continual learning setting for any data
stream without notion of task, class or domain.</p>
<p>Models only need to solve the task at hand; they are not required to
infer which task it is. In other words, task concept is not specific
now, but it also have the task.</p>
<p>The setting assumptions are: <span
class="math inline">\({\{\mathcal{Y}\}^t=
\{\mathcal{Y}^{t+1}\}}\)</span>, <span
class="math inline">\(P(\mathcal{Y}^t) =
P(\mathcal{Y}^{t+1})\)</span>.</p>
<h3
id="data-incremental-learning-task-agnostic-learning-the-hardest-scenario">Data
incremental Learning / Task-Agnostic Learning (the hardest
scenario)</h3>
<p>Task identity is not available even at training time! Task-Agnostic
Learning has no task concept at all, and it is the ideal condition of
Continual Learning. <img src="CL10.png"
alt="Task-Agnostic Learning" /></p>
<p>For a clearer understanding <strong>Task incremental
Learning</strong>,<strong>Class incremental Learning</strong> and
<strong>Domain incremental Learning</strong>, you can see the following
images<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>:</p>
<ul>
<li><p>Split Mnist Task: Split the number into different task. <img
src="CL8.png" alt="Split Mnist Task" /></p></li>
<li><p>Permuted Mnist Task: Permute each image in MNIST after
vectorization. Actually use a group of random indexes to disrupt the
position of each element in the vector(image). Different random indexes
will generate different tasks after being disrupted. <img src="CL9.png"
alt="Split Mnist Task" /></p></li>
</ul>
<h3 id="the-difference-between-continuous-learning-and-multi-task">The
difference between Continuous Learning and Multi-Task</h3>
<p><strong>Multi-Task Gradient Dynamics: Tug-of-War(ÊãîÊ≤≥ÊãâÈîØ)</strong>
<img src="CL19.png" alt="Multi Task" /></p>
<p>However, the tasks are not available simultaneously in CL! Need to
use some form of memory, or to modify the gradients, to still take into
account what solutions are good for previous tasks</p>
<h2 id="some-key-definitions">Some key definitionsÔºÅ</h2>
<h3 id="transfer-and-interference">Transfer and Interference</h3>
<p>Note: We need to maximize Transfer and minimize Interference. <img
src="CL20.png" alt="Transfer and interference" /></p>
<h3 id="possible-scenarios-in-cl">Possible Scenarios in CL</h3>
<figure>
<img src="CL21.png" alt="Possible Scenarios" />
<figcaption aria-hidden="true">Possible Scenarios</figcaption>
</figure>
<h2 id="the-method-of-continual-learning">The method of Continual
Learning</h2>
<p>Refer to Lange, M. D., et al.<a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a>, I try to draw a mind
mapping for better understand the current mainstream methods of
Continual Learning.</p>
<p>The define of each method<a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a>: ### Replay Methods As
you see, <strong>replay</strong> is the key. To realize
<strong>replay</strong>, this line of work should store samples in raw
format or generate pseudo-samples with a generative model (e.g.
GAN/diffusion model) because of privacy policy. Then, these previous
task samples are replayed while learning a new task to alleviate
forgetting. According to different ways of use, replay methods can be
divided into the following three categories:</p>
<p><strong>Rehearsal</strong> (Easy to implement, but poor performence
)</p>
<p>It is the esaiest way to understand. Just combine a limited subset of
stored samples(old tasks) into new task, and retrain the model.</p>
<ul>
<li>Advantage:
<ol type="1">
<li>Easy to implement</li>
</ol></li>
<li>Disadvantage:
<ol type="1">
<li>Be prone to overfitting the subset of stored samples.</li>
<li>Be bounded by joint training.</li>
</ol></li>
</ul>
<p><strong>Pseudo Rehearsal</strong></p>
<p>Feed random input to previous models, use the output as a
pseudo-sample. (Generative models are also used nowadays but add
training complexity.)<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></p>
<figure>
<img src="CL22.png" alt="Pseudo Rehearsal" />
<figcaption aria-hidden="true">Pseudo Rehearsal</figcaption>
</figure>
<p>Novel GR method<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a>: internal or hidden representations
are replayed that are generated by the network's own, context-modulated
feedback connections.</p>
<p><strong>Constrained Optimization</strong></p>
<p>Minimize interference with old tasks by constraining updates on the
new task. The goal is to optimize the loss on the current examples(s)
without increasing the losses on the previously learned examples.</p>
<p>Assume the examples are observed one at a time. Formulate the goal as
the following constrained optimization problem. <span
class="math display">\[\theta^{t}=\argmin_\theta \ell\left(f\left(x_{t}
; \theta\right), y_{t}\right)
\]</span> <span class="math display">\[s.t. \ell\left(f\left(x_{i} ;
\theta\right), y_{i}\right) \leq \ell\left(f\left(x_{i} ;
\theta^{t-1}\right), y_{i}\right) ; \forall i \in[0 \ldots
t-1]\]</span></p>
<p><span class="math inline">\(f(. ; \theta)\)</span> is a model
parameterized by <span class="math inline">\(\theta\)</span>, <span
class="math inline">\(\ell\)</span> is the loss function. <span
class="math inline">\(t\)</span> is the index of the current example and
<span class="math inline">\(i\)</span> indexes the previous
examples.</p>
<p>The original constraints can be rephrased to the constraints in the
gradient space:</p>
<p><span class="math display">\[
\left\langle g, g_{i}\right\rangle=\left\langle\frac{\partial
\ell\left(f\left(x_{t} ; \theta\right), y_{t}\right)}{\partial \theta},
\frac{\partial \ell\left(f\left(x_{i} ; \theta\right),
y_{i}\right)}{\partial \theta}\right\rangle \geq 0
\]</span></p>
<h3 id="regularization-based-methods">Regularization-Based Methods</h3>
<p>These method avoids storing raw inputs, prioritizing privacy, and
alleviating memory requirements. In these methods, an extra
regularization term is introduced in the loss function, to consolidate
previous knowledge when learning on new data. We can further divide
these methods into datafocused and prior-focused methods.<a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p><strong>Data-Focused Methods</strong></p>
<p>The basic building block in data-focused methods is <strong>knowledge
distillation</strong> from a previous model (trained on a previous task)
to the model being trained on the new data.</p>
<p><strong>Prior-Focused Methods</strong></p>
<p>To mitigate forgetting, prior-focused methods estimate a distribution
over the model parameters, used as prior when learning from new data.
Typically, importance of all neural network parameters is estimated,
with parameters assumed independent to ensure feasibility. During
training of later tasks, changes to important parameters are
penalized.</p>
<h3 id="parameter-isolation-methods">Parameter Isolation Methods</h3>
<p>This family dedicates different model parameters to each task, to
prevent any possible forgetting. These mehods avoid forgetting by using
different parameters for each task.</p>
<p>Best-suited for: task-incremental setting, unconstrained model
capacity, performance is the priority.</p>
<p><strong>Fixed Network Methods</strong> Network parts used for
previous tasks are masked out when learning new tasks (e.g., at neuronal
level (HAT) or at parameter level (PackNet, PathNet)</p>
<p><strong>Dynamic Architecture Methods</strong></p>
<p>When model size is not constrained: grow new branches for new tasks,
while freezing previous task parameters (RCL), or dedicate a model copy
to each task (Expert Gate), etc. <!-- # Â§ßÁ∫≤
Â§ßÁ∫≤Ôºö 
‰ªãÁªç‰∏Ä‰∏ã‰ªÄ‰πàÊòØCLÔºåÁªô‰∏Ä‰∏™High levelÁöÑÂÆö‰πâ„ÄÇ(Â∑≤ÂÆåÊàê)

ÊèèËø∞Âä®Êú∫Ôºå‰∫∫‰ª¨‰∏∫‰ªÄ‰πàÁ†îÁ©∂ËøôÁé©ÊÑèÂÑøÔºü(Â∑≤ÂÆåÊàê)

Áé∞Â≠òÈóÆÈ¢òÔºåËøôÁé©ÊÑèÂÑøÁõÆÂâçÂ≠òÂú®‰ªÄ‰πàÈóÆÈ¢òÔºü(Â∑≤ÂÆåÊàê)

‰∏Ä‰∫õËß£ÂÜ≥ÊñπÊ°àÔºå‰∫∫‰ª¨ÈÉΩÂÅö‰∫ÜÂì™‰∫õÂ∞ùËØïÔºü ‰∏ÄËà¨ÈÉΩÊòØÊàêÂäüÁöÑÂ∞ùËØïÔºåÂ§±Ë¥•ÁöÑÂ∞ùËØï‰∏çÂ•ΩÊâæ„ÄÇ
ÈúÄË¶ÅÂÅö‰∏Ä‰∏™ÁªüËÆ°Ôºö ÂåÖÂê´ ÊúÄÊó©ÁöÑCLÁöÑÊñáÁ´†Âá∫Áé∞ÁöÑÊó∂Èó¥ÔºåCLÈÄêÊ≠•ÂèòÂæóÁÅ´ÁàÜËµ∑Êù•ÁöÑÊó∂Èó¥ÔºåÂΩì‰∏ãCLÁöÑÁÉ≠ÁÇπÊñáÁ´†ÈÉΩÊúâÂì™‰∫õ„ÄÇÂπ∂ÂØπÂΩì‰∏ã‰∏Ä‰∫õÁöÑÁÉ≠ÁÇπÊñπÊ≥ïËøõË°åÁÆÄË¶ÅËÆ≤Ëß£„ÄÇ

ËøôÁé©ÊÑèÂÑøÁöÑÊú™Êù•Â¶Ç‰ΩïÔºåÂâçÊôØÂ¶Ç‰ΩïÔºü
Êú™Êù•ÂèØÊâ©Â±ïÁöÑÈÇ£‰∫õÊñπÂêë„ÄÇËøõË°å‰∏ÄÁÇπÁªÜËá¥ÁöÑËÆ≤Ëß£

 --></p>
<h2 id="conlusion">Conlusion</h2>
<p>TODO! Summaries will be added when i am familiar enough with this
field.</p>
<h2 id="appendix">Appendix:</h2>
<h3 id="mind-map">Mind Map</h3>
<figure>
<img src="CL23.png" alt="Mind Map" />
<figcaption aria-hidden="true">Mind Map</figcaption>
</figure>
<h3 id="some-representative-replay-methodskeep-updating">Some
representative Replay Methods(Keep updating):</h3>
<p>Only brief introduction, read the origional paper for more
information. #### iCaRL (incremental classifier and representation
learning)</p>
<p>iCaRL belongs to <strong>Rehearsal</strong> and <strong>Class
incremental Learning</strong>.</p>
<p>iCaRL, that allows learning in such a classincremental way: only the
training data for <strong>a small number of classes</strong>(NOT ALL
DATA! new data + some old data) has to be present at the same time and
<strong>new classes can be added progressively</strong>.</p>
<p>The author introduces three main components that in combination allow
iCaRL to fulfill all criteria put forth above.</p>
<ul>
<li><p>classification by a nearest-mean-of-exemplars rule</p></li>
<li><p>prioritized exemplar selection based on herding</p></li>
<li><p>representation learning using knowledge distillation and
prototype rehearsal.</p></li>
</ul>
<ol type="1">
<li><p>Classification (nearest-mean-of-exemplars)</p>
<p>Algorithm 1 describes the mean-of-exemplars classifier that is used
to classify images into the set of classes observed so far.</p>
<figure>
<img src="CL12.png" alt="Split Mnist Task" />
<figcaption aria-hidden="true">Split Mnist Task</figcaption>
</figure>
<p>where <span class="math inline">\(\mathcal{P} =
(P_1,\ldots,P_t)\)</span> is <strong>exemplar images</strong> that it
selects dynamically out of the data stream.</p>
<p>And <span class="math inline">\(t\)</span> denotes the number of
classes that have been observed so far(<span
class="math inline">\(t\)</span> increases with time).</p>
<p><span class="math inline">\(\varphi:\mathcal{X}\rightarrow
\mathbb{R}^d\)</span>, a trainable feature extractor, followed by a
single classification layer with as many sigmoid output nodes as classes
observed so far.</p>
<p>Class label <span class="math inline">\(y\in
\{1,\ldots,t\}\)</span>.</p></li>
<li><p>Training</p>
<p>For training, iCaRL processes batches of classes at a time using an
incremental learning strategy. Every time data for new classes is
available iCaRL calls an update routine (Algorithm 2)</p>
<figure>
<img src="CL13.png" alt="Split Mnist Task" />
<figcaption aria-hidden="true">Split Mnist Task</figcaption>
</figure></li>
<li><p>Other algorithm (For more detail, you can visit
10.1109/CVPR.2017.587) <img src="CL14.png" alt="Split Mnist Task" />
<img src="CL15.png" alt="Split Mnist Task" /></p></li>
</ol>
<h4 id="gem-gradient-episodic-memory-for-continual-learning6">GEM:
Gradient Episodic Memory for Continual Learning<a href="#fn9"
class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a></h4>
<p>Some important definition:</p>
<p>Note: Analogous to <strong>Transfer</strong> and
<strong>Interference</strong>. 1. <strong>Backward
transfer(BWT)</strong>, which is the influence that learning a current
task <span class="math inline">\(t\)</span> has on the performance on a
previous task <span class="math inline">\(k\)</span> (<span
class="math inline">\(k&lt;t\)</span>). - Positive Backward transfer:
There exists positive backward transfer when learning about some task t
increases the performance on some preceding task k. - Negative Backward
transfer: There also exists negative backward transfer when learning
about some task t decreases the performance on some preceding task k.
Large negative backward transfer is also known as <strong>catastrophic
forgetting</strong>. 2. <strong>Forward transfer(FWT)</strong>, which is
the influence that learning a current task t has on the performance on a
future task k (<span class="math inline">\(k&gt;t\)</span>). (Rarely
discussed because it is unpredictable) - Positive Forward transfer: In
particular, positive forward transfer is possible when the model is able
to perform ‚Äúzero-shot‚Äù learning, perhaps by exploiting the structure
available in the task descriptors.</p>
<p>Evaluation:</p>
<figure>
<img src="CL16.png" alt="Evaluation" />
<figcaption aria-hidden="true">Evaluation</figcaption>
</figure>
<p>GEM:</p>
<figure>
<img src="CL17.png" alt="GEM" />
<figcaption aria-hidden="true">GEM</figcaption>
</figure>
<p>Experiments: <img src="CL18.png" alt="Experiments" /></p>
<h1 id="for-more-blogs">For More Blogs</h1>
<p><strong>TODO</strong> : The future of Continue Learning.</p>
<p><strong>TODO</strong> : Details of some papers„ÄÇ</p>
<h1 id="reference-acknowledgements">Reference &amp;
Acknowledgements</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Wang, Z., et al. (2022). Learning To
Prompt for Continual Learning. Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR).<a href="#fnref1"
class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2" role="doc-endnote"><p>Rebuffi, S., et al. (2017). iCaRL:
Incremental Classifier and Representation Learning. 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR).<a href="#fnref2"
class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn3" role="doc-endnote"><p>Gido van de Ven and Andreas S.
Tolias.(2019) Three scenarios for continual learning. arXiv:1904.07734<a
href="#fnref3" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn4" role="doc-endnote"><p>Lange, M. D., et al. (2022). "A
Continual Learning Survey: Defying Forgetting in Classification Tasks."
Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7):
3366-3385.<a href="#fnref4" class="footnote-back"
role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn5" role="doc-endnote"><p>Lange, M. D., et al. (2022). "A
Continual Learning Survey: Defying Forgetting in Classification Tasks."
Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7):
3366-3385.<a href="#fnref5" class="footnote-back"
role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://icml.cc/virtual/2021/tutorial/10833 Part
of blog's pictures come from this link. Thanks :)<a href="#fnref6"
class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn7" role="doc-endnote"><p>van de Ven, G. M., et al. (2020).
"Brain-inspired replay for continual learning with artificial neural
networks." Nature Communications 11(1): 4069.<a href="#fnref7"
class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn8" role="doc-endnote"><p>Lange, M. D., et al. (2022). "A
Continual Learning Survey: Defying Forgetting in Classification Tasks."
Ieee Transactions on Pattern Analysis and Machine Intelligence 44(7):
3366-3385.<a href="#fnref8" class="footnote-back"
role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn9" role="doc-endnote"><p>Lopez-Paz, D. and M. t. A. Ranzato
(2017). Gradient Episodic Memory for Continual Learning. Advances in
Neural Information Processing Systems, Curran Associates, Inc.<a
href="#fnref9" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Continue-Learning-Life-long-Learning/" rel="tag"><i class="fa fa-tag"></i> Continue Learning / Life long Learning</a>
              <a href="/tags/Survey/" rel="tag"><i class="fa fa-tag"></i> Survey</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/26/The-Illustrated-Reservoir-sampling/" rel="next" title="ËøûÁª≠Â≠¶‰π†‰∏≠ÁöÑËìÑÊ∞¥Ê±†ÊäΩÊ†∑ÁÆóÊ≥ï(The Illustrated Reservoir sampling).">
                  ËøûÁª≠Â≠¶‰π†‰∏≠ÁöÑËìÑÊ∞¥Ê±†ÊäΩÊ†∑ÁÆóÊ≥ï(The Illustrated Reservoir sampling). <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yang Qi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>


  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
